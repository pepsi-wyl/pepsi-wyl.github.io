<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no"><title>Hadoop © pepsi-wyl | 伤寒杂病论 by pepsi-wyl</title><meta name="author" content="pepsi-wyl,pepsiwyl@gmail.com"><meta name="copyright" content="pepsi-wyl"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta name="description" content="Hadoop简介Hadoop是Apache软件基金会旗下的一个开源分布式计算平台，为用户提供了系统底层细节透明的分布式基础架构。Hadoop是基于Java语言开发的，具有很好的跨平台特性，并且可以部署在廉价的计算机集群中。Hadoop的核心是分布式文件系统（Hadoop Distributed File System，HDFS）和MapReduce。Apache Hadoop版本分为三代，分别是H">
<meta property="og:type" content="article">
<meta property="og:title" content="Hadoop © pepsi-wyl">
<meta property="og:url" content="https://ylan.site/2022/11/12/Hadoop-%C2%A9-pepsi-wyl/index.html">
<meta property="og:site_name" content="伤寒杂病论 by pepsi-wyl">
<meta property="og:description" content="Hadoop简介Hadoop是Apache软件基金会旗下的一个开源分布式计算平台，为用户提供了系统底层细节透明的分布式基础架构。Hadoop是基于Java语言开发的，具有很好的跨平台特性，并且可以部署在廉价的计算机集群中。Hadoop的核心是分布式文件系统（Hadoop Distributed File System，HDFS）和MapReduce。Apache Hadoop版本分为三代，分别是H">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://ylan.site/img/bg/bg7.jpg">
<meta property="article:published_time" content="2022-11-12T08:18:04.000Z">
<meta property="article:modified_time" content="2022-11-22T01:13:20.285Z">
<meta property="article:author" content="pepsi-wyl">
<meta property="article:tag" content="Hadoop">
<meta property="article:tag" content="大数据">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://ylan.site/img/bg/bg7.jpg"><link rel="shortcut icon" href="/img/favicon.png"><link rel="canonical" href="https://ylan.site/2022/11/12/Hadoop-%C2%A9-pepsi-wyl/"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//fonts.googleapis.com" crossorigin=""/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css" media="print" onload="this.media='all'"><link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Titillium+Web&amp;display=swap" media="print" onload="this.media='all'"><script>const GLOBAL_CONFIG = { 
  root: '/',
  algolia: undefined,
  localSearch: {"path":"/search.xml","preload":false,"languages":{"hits_empty":"找不到您查询的内容：${query}"}},
  translate: {"defaultEncoding":1,"translateDelay":0,"msgToTraditionalChinese":"繁","msgToSimplifiedChinese":"簡"},
  noticeOutdate: undefined,
  highlight: {"plugin":"highlighjs","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":false},
  copy: {
    success: '复制成功',
    error: '复制错误',
    noSupport: '浏览器不支持'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '天',
  date_suffix: {
    just: '刚刚',
    min: '分钟前',
    hour: '小时前',
    day: '天前',
    month: '个月前'
  },
  copyright: undefined,
  lightbox: 'mediumZoom',
  Snackbar: undefined,
  source: {
    justifiedGallery: {
      js: 'https://cdn.jsdelivr.net/npm/flickr-justified-gallery/dist/fjGallery.min.js',
      css: 'https://cdn.jsdelivr.net/npm/flickr-justified-gallery/dist/fjGallery.min.css'
    }
  },
  isPhotoFigcaption: false,
  islazyload: false,
  isAnchor: false
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: 'Hadoop © pepsi-wyl',
  isPost: true,
  isHome: false,
  isHighlightShrink: false,
  isToc: true,
  postUpdate: '2022-11-22 09:13:20'
}</script><noscript><style type="text/css">
  #nav {
    opacity: 1
  }
  .justified-gallery img {
    opacity: 1
  }

  #recent-posts time,
  #post-meta time {
    display: inline !important
  }
</style></noscript><script>(win=>{
    win.saveToLocal = {
      set: function setWithExpiry(key, value, ttl) {
        if (ttl === 0) return
        const now = new Date()
        const expiryDay = ttl * 86400000
        const item = {
          value: value,
          expiry: now.getTime() + expiryDay,
        }
        localStorage.setItem(key, JSON.stringify(item))
      },

      get: function getWithExpiry(key) {
        const itemStr = localStorage.getItem(key)

        if (!itemStr) {
          return undefined
        }
        const item = JSON.parse(itemStr)
        const now = new Date()

        if (now.getTime() > item.expiry) {
          localStorage.removeItem(key)
          return undefined
        }
        return item.value
      }
    }
  
    win.getScript = url => new Promise((resolve, reject) => {
      const script = document.createElement('script')
      script.src = url
      script.async = true
      script.onerror = reject
      script.onload = script.onreadystatechange = function() {
        const loadState = this.readyState
        if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
        script.onload = script.onreadystatechange = null
        resolve()
      }
      document.head.appendChild(script)
    })
  
      win.activateDarkMode = function () {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      win.activateLightMode = function () {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
        }
      }
      const t = saveToLocal.get('theme')
    
          if (t === 'dark') activateDarkMode()
          else if (t === 'light') activateLightMode()
        
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        if (asideStatus === 'hide') {
          document.documentElement.classList.add('hide-aside')
        } else {
          document.documentElement.classList.remove('hide-aside')
        }
      }
    
    const detectApple = () => {
      if(/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)){
        document.documentElement.classList.add('apple')
      }
    }
    detectApple()
    })(window)</script><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/font-awesome/css/font-awesome.min.css"><script src="/live2d-widget/autoload.js"></script><link rel="stylesheet" href="/css/background.css"><style>#article-container.post-content h1:before, h2:before, h3:before, h4:before, h5:before, h6:before { -webkit-animation: avatar_turn_around 1s linear infinite; -moz-animation: avatar_turn_around 1s linear infinite; -o-animation: avatar_turn_around 1s linear infinite; -ms-animation: avatar_turn_around 1s linear infinite; animation: avatar_turn_around 1s linear infinite; }</style><link rel="stylesheet" href="/css/weibo.css"><meta name="generator" content="Hexo 6.3.0"></head><body><div id="loading-box"><div class="loading-left-bg"></div><div class="loading-right-bg"></div><div class="spinner-box"><div class="configure-border-1"><div class="configure-core"></div></div><div class="configure-border-2"><div class="configure-core"></div></div><div class="loading-word">加载中...</div></div></div><script>const preloader = {
  endLoading: () => {
    document.body.style.overflow = 'auto';
    document.getElementById('loading-box').classList.add("loaded")
  },
  initLoading: () => {
    document.body.style.overflow = '';
    document.getElementById('loading-box').classList.remove("loaded")

  }
}
window.addEventListener('load',()=> { preloader.endLoading() })

if (false) {
  document.addEventListener('pjax:send', () => { preloader.initLoading() })
  document.addEventListener('pjax:complete', () => { preloader.endLoading() })
}</script><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img is-center"><img src="/img/ava.jpg" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"/></div><div class="sidebar-site-data site-data is-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">11</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">11</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">7</div></a></div><hr/><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page group" href="javascript:void(0);"><i class="fa-fw fas fa-list"></i><span> 文章</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> 时间轴</span></a></li><li><a class="site-page child" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> 标签</span></a></li><li><a class="site-page child" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 分类</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="/HTML/resume/resume.html"><i class="fa-fw fa fa-id-card"></i><span> 简历</span></a></div><div class="menus_item"><a class="site-page group" href="javascript:void(0);"><i class="fa-fw fas fa-file-code"></i><span> 小世界</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child" href="/HTML/demo/%E7%83%9F%E8%8A%B1.html"><i class="fa-fw fas fa-code"></i><span> 烟花效果</span></a></li><li><a class="site-page child" href="/HTML/demo/newyear/index.html"><i class="fa-fw fas fa-code"></i><span> 跨年烟花</span></a></li><li><a class="site-page child" href="/HTML/demo/fireworks/index.html"><i class="fa-fw fas fa-code"></i><span> 烟花模拟器</span></a></li><li><a class="site-page child" href="/HTML/demo/%E7%BA%B8%E9%A3%9E%E6%9C%BA.html"><i class="fa-fw fas fa-code"></i><span> 纸飞机</span></a></li><li><a class="site-page child" href="/HTML/demo/%E6%96%B9%E5%9D%97%E7%A9%BF%E6%A2%AD.html"><i class="fa-fw fas fa-code"></i><span> 方块穿梭</span></a></li><li><a class="site-page child" href="/HTML/demo/%E8%B6%85%E7%BA%A7%E7%8E%9B%E4%B8%BD.html"><i class="fa-fw fas fa-code"></i><span> 超级玛丽</span></a></li><li><a class="site-page child" href="/HTML/demo/%E8%B4%AA%E5%90%83%E8%9B%87.html"><i class="fa-fw fas fa-code"></i><span> 贪吃蛇</span></a></li><li><a class="site-page child" href="/HTML/demo/3D-Heart/index.html"><i class="fa-fw fas fa-code"></i><span> 3D爱心</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-link"></i><span> 友链</span></a></div></div></div></div><div class="post" id="body-wrap"><header class="post-bg" id="page-header" style="background-image: url('/img/bg/bg7.jpg')"><nav id="nav"><span id="blog_name"><a id="site-name" href="/">伤寒杂病论 by pepsi-wyl</a></span><div id="he-plugin-simple"></div><div id="none_space"></div><div id="menus"><div id="search-button"><a class="site-page social-icon search"><i class="fas fa-search fa-fw"></i><span> 搜索</span></a></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page group" href="javascript:void(0);"><i class="fa-fw fas fa-list"></i><span> 文章</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> 时间轴</span></a></li><li><a class="site-page child" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> 标签</span></a></li><li><a class="site-page child" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 分类</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="/HTML/resume/resume.html"><i class="fa-fw fa fa-id-card"></i><span> 简历</span></a></div><div class="menus_item"><a class="site-page group" href="javascript:void(0);"><i class="fa-fw fas fa-file-code"></i><span> 小世界</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child" href="/HTML/demo/%E7%83%9F%E8%8A%B1.html"><i class="fa-fw fas fa-code"></i><span> 烟花效果</span></a></li><li><a class="site-page child" href="/HTML/demo/newyear/index.html"><i class="fa-fw fas fa-code"></i><span> 跨年烟花</span></a></li><li><a class="site-page child" href="/HTML/demo/fireworks/index.html"><i class="fa-fw fas fa-code"></i><span> 烟花模拟器</span></a></li><li><a class="site-page child" href="/HTML/demo/%E7%BA%B8%E9%A3%9E%E6%9C%BA.html"><i class="fa-fw fas fa-code"></i><span> 纸飞机</span></a></li><li><a class="site-page child" href="/HTML/demo/%E6%96%B9%E5%9D%97%E7%A9%BF%E6%A2%AD.html"><i class="fa-fw fas fa-code"></i><span> 方块穿梭</span></a></li><li><a class="site-page child" href="/HTML/demo/%E8%B6%85%E7%BA%A7%E7%8E%9B%E4%B8%BD.html"><i class="fa-fw fas fa-code"></i><span> 超级玛丽</span></a></li><li><a class="site-page child" href="/HTML/demo/%E8%B4%AA%E5%90%83%E8%9B%87.html"><i class="fa-fw fas fa-code"></i><span> 贪吃蛇</span></a></li><li><a class="site-page child" href="/HTML/demo/3D-Heart/index.html"><i class="fa-fw fas fa-code"></i><span> 3D爱心</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-link"></i><span> 友链</span></a></div></div><div id="toggle-menu"><a class="site-page"><i class="fas fa-bars fa-fw"></i></a></div></div></nav><div id="post-info"><h1 class="post-title">Hadoop © pepsi-wyl</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">发表于</span><time class="post-meta-date-created" datetime="2022-11-12T08:18:04.000Z" title="发表于 2022-11-12 16:18:04">2022-11-12</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">更新于</span><time class="post-meta-date-updated" datetime="2022-11-22T01:13:20.285Z" title="更新于 2022-11-22 09:13:20">2022-11-22</time></span><span class="post-meta-categories"><span class="post-meta-separator">|</span><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/">大数据</a></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-wordcount"><i class="far fa-file-word fa-fw post-meta-icon"></i><span class="post-meta-label">字数总计:</span><span class="word-count">10.1k</span><span class="post-meta-separator">|</span><i class="far fa-clock fa-fw post-meta-icon"></i><span class="post-meta-label">阅读时长:</span><span>51分钟</span></span><span class="post-meta-separator">|</span><span class="post-meta-pv-cv" id="" data-flag-title="Hadoop © pepsi-wyl"><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">阅读量:</span><span id="busuanzi_value_page_pv"><i class="fa-solid fa-spinner fa-spin"></i></span></span></div></div></div></header><main class="layout" id="content-inner"><div id="post"><article class="post-content" id="article-container"><h1 id="Hadoop简介"><a href="#Hadoop简介" class="headerlink" title="Hadoop简介"></a>Hadoop简介</h1><p>Hadoop是Apache软件基金会旗下的一个开源分布式计算平台，为用户提供了系统底层细节透明的分布式基础架构。Hadoop是基于Java语言开发的，具有很好的跨平台特性，并且可以部署在廉价的计算机集群中。Hadoop的核心是分布式文件系统（Hadoop Distributed File System，HDFS）和MapReduce。Apache Hadoop版本分为三代，分别是Hadoop 1.0、Hadoop 2.0和Hadoop3.0。除了免费开源的Apache Hadoop以外，还有一些商业公司推出Hadoop的发行版。2008年，Cloudera成为第一个Hadoop商业化公司，并在2009年推出第一个Hadoop发行版。此后，很多大公司也加入了做Hadoop产品化的行列，比如MapR、Hortonworks、星环等。2018年10月，Cloudera和Hortonworks宣布合并。一般而言，商业化公司推出的Hadoop发行版也是以Apache Hadoop为基础，但是前者比后者具有更好的易用性、更多的功能以及更高的性能。</p>
<h1 id="单机安装"><a href="#单机安装" class="headerlink" title="单机安装"></a>单机安装</h1><h2 id="预先配置"><a href="#预先配置" class="headerlink" title="预先配置"></a>预先配置</h2><h3 id="关闭防火墙"><a href="#关闭防火墙" class="headerlink" title="关闭防火墙"></a>关闭防火墙</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 关闭</span></span><br><span class="line">systemctl stop firewalld</span><br><span class="line"><span class="comment"># 禁止开机自启</span></span><br><span class="line">systemctl <span class="built_in">disable</span> firewalld</span><br></pre></td></tr></table></figure>

<h3 id="修改主机名称和添加映射"><a href="#修改主机名称和添加映射" class="headerlink" title="修改主机名称和添加映射"></a>修改主机名称和添加映射</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 修改主机名称</span></span><br><span class="line">hostnamectl set-hostname hadoop</span><br><span class="line"></span><br><span class="line"><span class="comment"># 添加映射</span></span><br><span class="line">vim /etc/hosts</span><br><span class="line">192.168.131.144 hadoop</span><br></pre></td></tr></table></figure>

<h3 id="创建Hadoop用户"><a href="#创建Hadoop用户" class="headerlink" title="创建Hadoop用户"></a>创建Hadoop用户</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 创建用户并使用 /bin/bash 作为shell</span></span><br><span class="line">useradd -m hadoop -s /bin/bash</span><br><span class="line"></span><br><span class="line"><span class="comment"># 给hadoop用户设置密码，若提示密码无效，不用管，接着输入一次即可</span></span><br><span class="line">passwd hadoop</span><br><span class="line"></span><br><span class="line"><span class="comment"># 给hadoop增加执行权限</span></span><br><span class="line">visudo</span><br><span class="line"><span class="comment">#98行  输入 :98 跳转至98行，增加一行 hadoop  ALL=(ALL) ALL</span></span><br><span class="line">root   ALL=(ALL) ALL</span><br><span class="line">hadoop ALL=(ALL) ALL</span><br></pre></td></tr></table></figure>

<h3 id="设置SSH免密登陆"><a href="#设置SSH免密登陆" class="headerlink" title="设置SSH免密登陆"></a>设置SSH免密登陆</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 连续敲击3次回车</span></span><br><span class="line">ssh-keygen -t rsa</span><br></pre></td></tr></table></figure>
<img src="/2022/11/12/Hadoop-%C2%A9-pepsi-wyl/1663641733146-a8455665-58ee-40e3-a010-2bf11716ce01.png" class="">
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 查看生成的秘钥对</span></span><br><span class="line"><span class="built_in">ls</span> ~/.ssh/ </span><br></pre></td></tr></table></figure>
<img src="/2022/11/12/Hadoop-%C2%A9-pepsi-wyl/1663641760536-97777943-3817-457e-adf0-f77610436ebd.png" class="">
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 追加公钥，执行命令后，根据提示输入 yes 再次回车</span></span><br><span class="line">ssh-copy-id hadoop</span><br></pre></td></tr></table></figure>
<img src="/2022/11/12/Hadoop-%C2%A9-pepsi-wyl/1663641803197-e32579dd-bef8-460f-afc3-11123ca453d4.png" class="">
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 查看生成的认证文件 authorized_keys</span></span><br><span class="line"><span class="built_in">ls</span> ~/.ssh/ authorized_keys id_rsa id_rsa.pub known_hosts</span><br></pre></td></tr></table></figure>
<img src="/2022/11/12/Hadoop-%C2%A9-pepsi-wyl/1663641836828-57203ca4-ed25-4f44-b55a-c43f1617fea5.png" class="">
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 验证免密</span></span><br><span class="line">ssh hadoop</span><br><span class="line">ssh 192.168.131.144</span><br><span class="line"><span class="comment"># 退出</span></span><br><span class="line"><span class="built_in">exit</span></span><br></pre></td></tr></table></figure>
<img src="/2022/11/12/Hadoop-%C2%A9-pepsi-wyl/1663641915104-1b41fa2d-da76-4f02-8de6-3b396efca443.png" class=""> 

<h3 id="安装JAVA并配置环境变量"><a href="#安装JAVA并配置环境变量" class="headerlink" title="安装JAVA并配置环境变量"></a>安装JAVA并配置环境变量</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">上传至服务器并且解压更改名称</span></span><br><span class="line">tar -xvzf jdk-8u351-linux-x64.tar.gz </span><br><span class="line">mv jdk-8u351 jdk8</span><br></pre></td></tr></table></figure>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">编辑配置文件</span></span><br><span class="line">vim /etc/profile </span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">设置jdk环境变量</span></span><br><span class="line">export JAVA_HOME=/home/hadoop/jdk8  #jdk安装目录</span><br><span class="line">export JRE_HOME=$&#123;JAVA_HOME&#125;/jre</span><br><span class="line">export CLASSPATH=.:$&#123;JAVA_HOME&#125;/lib:$&#123;JRE_HOME&#125;/lib:$CLASSPATH</span><br><span class="line">export JAVA_PATH=$&#123;JAVA_HOME&#125;/bin:$&#123;JRE_HOME&#125;/bin</span><br><span class="line">export PATH=$PATH:$&#123;JAVA_PATH&#125;</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">使配置文件生效</span></span><br><span class="line">source /etc/profile</span><br></pre></td></tr></table></figure>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">检查是否安装成功</span></span><br><span class="line">java -version</span><br></pre></td></tr></table></figure>
<img src="/2022/11/12/Hadoop-%C2%A9-pepsi-wyl/1663589572984-3f8831f9-bdb3-48ff-a4a0-cd1f2dd7bfdc.png" class=""> 

<h3 id="安装Hadoop并配置环境变量"><a href="#安装Hadoop并配置环境变量" class="headerlink" title="安装Hadoop并配置环境变量"></a>安装Hadoop并配置环境变量</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">上传至服务器并且解压更改名称</span></span><br><span class="line">tar -zxvf hadoop-3.1.3.tar.gz</span><br><span class="line">mv hadoop-3.1.3 hadoop</span><br></pre></td></tr></table></figure>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">查看是否可用</span></span><br><span class="line">/home/hadoop/hadoop/bin/hadoop version</span><br></pre></td></tr></table></figure>
<img src="/2022/11/12/Hadoop-%C2%A9-pepsi-wyl/1667010092554-700f0aa9-b031-4e92-b770-500fdb34f7d3.png" class=""> 
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">编辑profile文件</span></span><br><span class="line">vim /etc/profile</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">增加hadoop环境变量</span></span><br><span class="line">export HADOOP_HOME=/home/hadoop/hadoop</span><br><span class="line">export PATH=$PATH:$HADOOP_HOME/bin:$HADOOP_HOME/sbin</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">使配置文件生效</span></span><br><span class="line">source /etc/profile</span><br></pre></td></tr></table></figure>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hadoop version</span><br></pre></td></tr></table></figure>
<img src="/2022/11/12/Hadoop-%C2%A9-pepsi-wyl/1667010077535-4ce9cd5c-e0a2-43d2-bf07-b66d2bd4dd60.png" class=""> 

<h2 id="单机非分布式运行"><a href="#单机非分布式运行" class="headerlink" title="单机非分布式运行"></a>单机非分布式运行</h2><p>主要<strong>用来调试时使用</strong></p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">进入hadoop的安装路径</span></span><br><span class="line">cd /home/hadoop/hadoop</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">将配置文件作为输入文件</span></span><br><span class="line">mkdir ./input</span><br><span class="line">cp ./etc/hadoop/*.xml ./input   </span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">运行</span></span><br><span class="line">./bin/hadoop jar ./share/hadoop/mapreduce/hadoop-mapreduce-examples-*.jar grep ./input ./output &#x27;dfs[a-z.]+&#x27;</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">查看</span></span><br><span class="line">cat ./output/*</span><br><span class="line"></span><br><span class="line">//  rm -rf ./input</span><br><span class="line">//  rm -rf ./input</span><br></pre></td></tr></table></figure>

<h2 id="伪分布式运行"><a href="#伪分布式运行" class="headerlink" title="伪分布式运行"></a>伪分布式运行</h2><h3 id="创建hadoop存放数据的目录"><a href="#创建hadoop存放数据的目录" class="headerlink" title="创建hadoop存放数据的目录"></a>创建hadoop存放数据的目录</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 切换路径 hadoop的安装路径</span></span><br><span class="line"><span class="built_in">cd</span> /home/hadoop/hadoop/</span><br><span class="line"></span><br><span class="line"><span class="comment"># 创建 temp 路径</span></span><br><span class="line"><span class="built_in">mkdir</span> temp</span><br><span class="line"><span class="comment"># 创建 dfs 路径</span></span><br><span class="line"><span class="built_in">cd</span> temp/</span><br><span class="line"><span class="built_in">mkdir</span> dfs</span><br><span class="line"><span class="comment"># 创建 name 和 data 文件夹</span></span><br><span class="line"><span class="built_in">cd</span> dfs/</span><br><span class="line"><span class="built_in">mkdir</span> name</span><br><span class="line"><span class="built_in">mkdir</span> data</span><br><span class="line"></span><br><span class="line"><span class="built_in">ls</span></span><br><span class="line">data  name</span><br></pre></td></tr></table></figure>
<img src="/2022/11/12/Hadoop-%C2%A9-pepsi-wyl/1663643055647-d3d78508-7abd-4a39-ac98-ad2fb4d27fc1.png" class=""> 

<h3 id="修改配置文件"><a href="#修改配置文件" class="headerlink" title="修改配置文件"></a>修改配置文件</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">hadoop 配置文件都在hadoop 安装目录下的 /etc/hadoop 中</span></span><br><span class="line">cd /home/hadoop/hadoop/etc/hadoop</span><br></pre></td></tr></table></figure>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">vim hadoop-env.sh</span><br></pre></td></tr></table></figure>
<img src="/2022/11/12/Hadoop-%C2%A9-pepsi-wyl/1663588736101-ee11adc3-4272-4fa2-a63d-09206419ae05.png" class=""> 
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line">vim core-site.xml</span><br><span class="line"></span><br><span class="line">&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;</span><br><span class="line">&lt;?xml-stylesheet type=&quot;text/xsl&quot; href=&quot;configuration.xsl&quot;?&gt;</span><br><span class="line">&lt;configuration&gt;</span><br><span class="line">    &lt;!-- 指定 使用哪种文件系统--&gt;</span><br><span class="line">    &lt;property&gt;</span><br><span class="line">        &lt;name&gt;fs.defaultFS&lt;/name&gt;</span><br><span class="line">        &lt;!-- 使用系hdfs分布式统--&gt;</span><br><span class="line">        &lt;!-- hdfs系统地址 hdfs://hdfs集群主节点名称:9000(默认端口号)--&gt;</span><br><span class="line">        &lt;!--因为是伪分布式,所有节点在同一台机子上,故节点名称为主机名--&gt;</span><br><span class="line">        &lt;value&gt;hdfs://hadoop:9000&lt;/value&gt;</span><br><span class="line">    &lt;/property&gt;</span><br><span class="line">    &lt;!-- 指定hadoop进程工作目录,hadoop运行时产生文件的存储路径--&gt;</span><br><span class="line">    &lt;property&gt;</span><br><span class="line">        &lt;name&gt;hadoop.tmp.dir&lt;/name&gt;</span><br><span class="line">        &lt;!--数据放在hadoop的安装目录下是/tmp下--&gt;</span><br><span class="line">        &lt;value&gt;/home/hadoop/hadoop/tmp/&lt;/value&gt;</span><br><span class="line">        &lt;description&gt;A base for other temporary directories.&lt;/description&gt;</span><br><span class="line">    &lt;/property&gt;</span><br><span class="line">    &lt;property&gt;</span><br><span class="line">        &lt;name&gt;hadoop.http.staticuser.user&lt;/name&gt;</span><br><span class="line">        &lt;value&gt;root&lt;/value&gt;</span><br><span class="line">    &lt;/property&gt;</span><br><span class="line">&lt;/configuration&gt;</span><br></pre></td></tr></table></figure>
<img src="/2022/11/12/Hadoop-%C2%A9-pepsi-wyl/1663643912934-f5df4cc6-5ebc-4af5-b93b-fe6c360ac6bd.png" class=""> 
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line">vim hdfs-site.xml</span><br><span class="line"></span><br><span class="line">&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;</span><br><span class="line">&lt;?xml-stylesheet type=&quot;text/xsl&quot; href=&quot;configuration.xsl&quot;?&gt;</span><br><span class="line">&lt;configuration&gt;</span><br><span class="line">    &lt;property&gt;</span><br><span class="line">        &lt;!--指定HDFS储存数据的副本数目，默认情况下为3份--&gt;</span><br><span class="line">        &lt;name&gt;dfs.replication&lt;/name&gt;</span><br><span class="line">        &lt;value&gt;1&lt;/value&gt;</span><br><span class="line">    &lt;/property&gt;</span><br><span class="line">    &lt;property&gt;</span><br><span class="line">        &lt;!--name node 存放 name table 的目录--&gt;</span><br><span class="line">        &lt;name&gt;dfs.namenode.name.dir&lt;/name&gt;</span><br><span class="line">        &lt;value&gt;/home/hadoop/hadoop/tmp/dfs/name&lt;/value&gt;</span><br><span class="line">    &lt;/property&gt;</span><br><span class="line">    &lt;property&gt;</span><br><span class="line">        &lt;!--data node 存放数据 block 的目录--&gt;</span><br><span class="line">        &lt;name&gt;dfs.datanode.data.dir&lt;/name&gt;</span><br><span class="line">        &lt;value&gt;/home/hadoop/hadoop/tmp/dfs/data&lt;/value&gt;</span><br><span class="line">    &lt;/property&gt;</span><br><span class="line">    &lt;property&gt;</span><br><span class="line">        &lt;!--设置监控页面的端口及地址--&gt;</span><br><span class="line">        &lt;name&gt;dfs.http.address&lt;/name&gt;</span><br><span class="line">        &lt;value&gt;0.0.0.0:50070&lt;/value&gt;</span><br><span class="line">    &lt;/property&gt;</span><br><span class="line">&lt;/configuration&gt;</span><br></pre></td></tr></table></figure>
<img src="/2022/11/12/Hadoop-%C2%A9-pepsi-wyl/1663643954561-840c2b58-6b0d-4c1f-9826-df75a6868327.png" class=""> 
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">vim mapred-site.xml</span><br><span class="line"></span><br><span class="line">&lt;?xml version=&quot;1.0&quot;?&gt;</span><br><span class="line">&lt;?xml-stylesheet type=&quot;text/xsl&quot; href=&quot;configuration.xsl&quot;?&gt;</span><br><span class="line">&lt;configuration&gt;</span><br><span class="line">    &lt;!-- 通知框架mapreduce使用YARN --&gt;</span><br><span class="line">    &lt;!-- 使得mapreduce在资源调度集群(yarn)上跑--&gt;</span><br><span class="line">    &lt;property&gt;</span><br><span class="line">        &lt;name&gt;mapreduce.framework.name&lt;/name&gt;</span><br><span class="line">        &lt;value&gt;yarn&lt;/value&gt;</span><br><span class="line">    &lt;/property&gt;</span><br><span class="line">&lt;/configuration&gt;</span><br></pre></td></tr></table></figure>
<img src="/2022/11/12/Hadoop-%C2%A9-pepsi-wyl/1663643968145-60c65faa-0070-46b0-bb9c-c982462179f1.png" class=""> 
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">vim yarn-site.xml</span><br><span class="line"></span><br><span class="line">&lt;?xml version=&quot;1.0&quot;?&gt;</span><br><span class="line">&lt;configuration&gt;</span><br><span class="line">    &lt;!-- 配置yarn 集群主节点，因为是伪分布式,所以是本机--&gt;</span><br><span class="line">    &lt;property&gt;</span><br><span class="line">        &lt;name&gt;yarn.resourcemanager.hostname&lt;/name&gt;</span><br><span class="line">        &lt;value&gt;hadoop&lt;/value&gt;</span><br><span class="line">    &lt;/property&gt;</span><br><span class="line">    &lt;!-- reducer取数据的方式是mapreduce_shuffle --&gt;</span><br><span class="line">    &lt;!-- node-manager 从节点 --&gt;</span><br><span class="line">    &lt;property&gt;</span><br><span class="line">        &lt;name&gt;yarn.nodemanager.aux-services&lt;/name&gt;</span><br><span class="line">        &lt;value&gt;mapreduce_shuffle&lt;/value&gt;</span><br><span class="line">    &lt;/property&gt;</span><br><span class="line">&lt;/configuration&gt;</span><br></pre></td></tr></table></figure>
<img src="/2022/11/12/Hadoop-%C2%A9-pepsi-wyl/1663643979365-99107655-9c0b-4c81-89eb-4749467a4635.png" class=""> 

<h3 id="修改环境变量"><a href="#修改环境变量" class="headerlink" title="修改环境变量"></a>修改环境变量</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">编辑配置文件</span></span><br><span class="line">vim /etc/profile</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">添加环境变量</span></span><br><span class="line">export HDFS_NAMENODE_USER=root</span><br><span class="line">export HDFS_DATANODE_USER=root</span><br><span class="line">export HDFS_SECONDARYNAMENODE_USER=root</span><br><span class="line">export YARN_RESOURCEMANAGER_USER=root</span><br><span class="line">export YARN_NODEMANAGER_USER=root</span><br><span class="line"></span><br><span class="line">export HADOOP_COMMON_LIB_NATIVE_DIR=$HADOOP_HOME/lib/native </span><br><span class="line">export HADOOP_OPTS=&quot;-Djava.library.path=$HADOOP_HOME/lib&quot; </span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">使配置文件生效</span></span><br><span class="line">source /etc/profile</span><br></pre></td></tr></table></figure>
<img src="/2022/11/12/Hadoop-%C2%A9-pepsi-wyl/1663591945147-337ce9f4-f46b-421e-9094-e16e29bc6815.png" class=""> 

<h3 id="格式化集群文件系统"><a href="#格式化集群文件系统" class="headerlink" title="格式化集群文件系统"></a>格式化集群文件系统</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hadoop namenode -format</span><br></pre></td></tr></table></figure>
<img src="/2022/11/12/Hadoop-%C2%A9-pepsi-wyl/1663589892367-51dfc120-6ae4-487f-a171-a38e28fac7b5.png" class=""> 

<h3 id="启动伪分布式"><a href="#启动伪分布式" class="headerlink" title="启动伪分布式"></a>启动伪分布式</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">start-all.sh</span><br></pre></td></tr></table></figure>
<img src="/2022/11/12/Hadoop-%C2%A9-pepsi-wyl/1663643207913-53599cf3-06c0-4445-8c7b-bbdc6500ed7d.png" class=""> 
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">jps</span><br></pre></td></tr></table></figure>
<img src="/2022/11/12/Hadoop-%C2%A9-pepsi-wyl/1663643216928-c8bf1643-b2da-46b0-803b-55f3c11de072.png" class=""> 

<h3 id="Web管理界面（关闭防火墙或者放行端口）"><a href="#Web管理界面（关闭防火墙或者放行端口）" class="headerlink" title="Web管理界面（关闭防火墙或者放行端口）"></a>Web管理界面（关闭防火墙或者放行端口）</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">http://192.168.131.144:50070/</span><br></pre></td></tr></table></figure>
<img src="/2022/11/12/Hadoop-%C2%A9-pepsi-wyl/1663643420268-4ba15f66-5fb6-4ff8-9b5d-9c0efa937e3f.png" class=""> 
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">http://192.168.131.144:8088</span><br></pre></td></tr></table></figure>
<img src="/2022/11/12/Hadoop-%C2%A9-pepsi-wyl/1663643396447-7f745750-2777-436b-ae27-d05d2124a275.png" class=""> 

<h3 id="关闭伪分布式"><a href="#关闭伪分布式" class="headerlink" title="关闭伪分布式"></a>关闭伪分布式</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">stop-all.sh</span><br></pre></td></tr></table></figure>
<img src="/2022/11/12/Hadoop-%C2%A9-pepsi-wyl/1663644320334-099a2dcd-8cb0-4687-aec9-d9ec2e5e7e0c.png" class=""> 

<h1 id="分布式安装-选作"><a href="#分布式安装-选作" class="headerlink" title="分布式安装(选作)"></a>分布式安装(选作)</h1><h2 id="虚机分配"><a href="#虚机分配" class="headerlink" title="虚机分配"></a>虚机分配</h2><table>
<thead>
<tr>
<th></th>
<th>hadoop1:192.168.131.145</th>
<th>hadoop2:192.168.131.146</th>
<th>hadoop3:192.168.131.147</th>
</tr>
</thead>
<tbody><tr>
<td>HDFS</td>
<td>NameNode<br />DataNode</td>
<td>DataNode</td>
<td>SecondaryNameNode<br />DataNode</td>
</tr>
<tr>
<td>YARN</td>
<td>NodeManager</td>
<td>ResourceManager<br />NodeManager</td>
<td>NodeManager</td>
</tr>
</tbody></table>
<p>克隆3台虚拟机修改静态IP进行操作</p>
<h2 id="准备工作"><a href="#准备工作" class="headerlink" title="准备工作"></a>准备工作</h2><h3 id="关闭防火墙-3台"><a href="#关闭防火墙-3台" class="headerlink" title="关闭防火墙(3台)"></a>关闭防火墙(3台)</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">关闭</span></span><br><span class="line">systemctl stop firewalld</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">禁止开机自启</span></span><br><span class="line">systemctl disable firewalld</span><br></pre></td></tr></table></figure>

<h3 id="修改主机名称和修改映射-3台"><a href="#修改主机名称和修改映射-3台" class="headerlink" title="修改主机名称和修改映射(3台)"></a>修改主机名称和修改映射(3台)</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">修改主机名称</span></span><br><span class="line">hostnamectl set-hostname hadoop1</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">添加映射</span></span><br><span class="line">vim /etc/hosts</span><br><span class="line">192.168.131.145 hadoop1</span><br><span class="line">192.168.131.146 hadoop2</span><br><span class="line">192.168.131.147 hadoop3</span><br></pre></td></tr></table></figure>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">修改主机名称</span></span><br><span class="line">hostnamectl set-hostname hadoop2</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">添加映射</span></span><br><span class="line">vim /etc/hosts</span><br><span class="line">192.168.131.145 hadoop1</span><br><span class="line">192.168.131.146 hadoop2</span><br><span class="line">192.168.131.147 hadoop3</span><br></pre></td></tr></table></figure>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">修改主机名称</span></span><br><span class="line">hostnamectl set-hostname hadoop3</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">添加映射</span></span><br><span class="line">vim /etc/hosts</span><br><span class="line">192.168.131.145 hadoop1</span><br><span class="line">192.168.131.146 hadoop2</span><br><span class="line">192.168.131.147 hadoop3</span><br></pre></td></tr></table></figure>

<h3 id="设置SSH免密登陆-3台"><a href="#设置SSH免密登陆-3台" class="headerlink" title="设置SSH免密登陆(3台)"></a>设置SSH免密登陆(3台)</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">3次回车</span></span><br><span class="line">ssh-keygen -t rsa</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">私钥和公钥 /root/.ssh 里</span></span><br><span class="line">cd /root/.ssh</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">创建一个名为 authorized_keys 的文件</span></span><br><span class="line">touch authorized_keys</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">将公钥写进这个文件</span></span><br><span class="line">cat id_rsa.pub &gt;&gt; authorized_keys   # 该文件当前只存贮了本机的公钥私钥</span><br></pre></td></tr></table></figure>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">3台主机的全部公钥私钥在3台机器上全部存储(粗暴复制)</span></span><br><span class="line"></span><br><span class="line">ssh-rsa AAAAB3NzaC1yc2EAAAADAQABAAABAQDkJjZnDNzV+m87Ox6RanAJW4Wl3ZXHJSumNcoXitLTew9NMWmliK7nl87iWOP7iAuqIwgv0mowaO9J8wDUjCqhv2gQymNDR+tKcX1DNIgrR8xdO2jHjmi2NsyihoMgVUbs27mFaznPiJprSEEznE9GZgoQ5C27QKxG2f03p1dWiPJHNfcf4EJO1V/2YI+u1hprKkoZFoZr7q6c5fTJkRSn6BBFXKHQOeQTTdrbeJA4zdUO/Rb/0jWTuhUFU52hfgQtzmEhDKiE2N19eG78p7QLvY4clcaYDg9m1p8I9HeXVMAp7pg+d3NadksXlzWEbyF5BTc3wHYXhC0bv6yhplI5 root@hadoop1</span><br><span class="line">ssh-rsa AAAAB3NzaC1yc2EAAAADAQABAAABAQDs02adR7MDyNeVwarqoKlyNIfZjUHi8zgZjzbVTattM9GwvF/FC0rRzjOYjexpjpyA0IVOm5ililEwMX8yjJhhx7h004OKdl39O642dtr8Pnf/SEy8cLPilnGO0n3lXIXzpqekTHQ3czlE3X9UDfG1BcYJcOIkD4ltlAXkS7bnosqoN/Eu82Dec1AsyjCITWayAQcC0fMsTlKKWgh8sBaXIjdYwrAh9WbZjyatYnWnTBxtqDXhZhDHc9QdWaq0pYtrMGQ7ZZ2weqfKDY9+7wEwBgkg7SmJhkwtVDiuO8Xef9geFmnHzKrpTCel+J3EfwHYOV0yMWAvZ2TFo271ogk3 root@hadoop2</span><br><span class="line">ssh-rsa AAAAB3NzaC1yc2EAAAADAQABAAABAQDpZFNA4qlYVrPcVIULo41h6y8qr2EJW7xj4JM9K3kLqFZ1tQw2voN9VA91GlOwKI1lvCVWyuwnkQaWLXHN3M56Jdpw9pupNt3LAXjEmLl+8Ze1vfbgv7DoVS9yJyJQn8V/AKZE3xl/AftrY8anMtYAIujwEn1M5Fra4ozLTfRRmB0Duax/Qgi2xCHaq90YldKcwI4pZ2nz1y9ffwhLR1wKQUJBGyhVIshw8a/vkrnjNGcUwa7fe55SelOEl5bSOgcTGeXHaQufGmnHslwrc91Qzd+W2peaF2ChDCoob+wIqJq7liqMeZw6go/IN+VSWkF4EXwKu4RPaY+bHj9EUlT9 root@hadoop3</span><br></pre></td></tr></table></figure>

<h3 id="安装JDK并配置环境变量-3台"><a href="#安装JDK并配置环境变量-3台" class="headerlink" title="安装JDK并配置环境变量(3台)"></a>安装JDK并配置环境变量(3台)</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">上传至服务器并且解压更改名称</span></span><br><span class="line">tar -xvzf jdk-8u333-linux-i586.tar.gz </span><br><span class="line">mv jdk1.8.0_333 jdk8</span><br><span class="line">rm -rf jdk-8u333-linux-i586.tar.gz</span><br></pre></td></tr></table></figure>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">编辑配置文件</span></span><br><span class="line">vim /etc/profile</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">设置jdk环境变量</span></span><br><span class="line">export JAVA_HOME=/opt/jdk8  #jdk安装目录</span><br><span class="line">export JRE_HOME=$&#123;JAVA_HOME&#125;/jre</span><br><span class="line">export CLASSPATH=.:$&#123;JAVA_HOME&#125;/lib:$&#123;JRE_HOME&#125;/lib:$CLASSPATH</span><br><span class="line">export JAVA_PATH=$&#123;JAVA_HOME&#125;/bin:$&#123;JRE_HOME&#125;/bin</span><br><span class="line">export PATH=$PATH:$&#123;JAVA_PATH&#125;</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">使配置文件生效</span></span><br><span class="line">source /etc/profile</span><br></pre></td></tr></table></figure>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">检查是否安装成功</span></span><br><span class="line">java -version</span><br></pre></td></tr></table></figure>

<h3 id="安装Hadoop并配置环境变量-3台"><a href="#安装Hadoop并配置环境变量-3台" class="headerlink" title="安装Hadoop并配置环境变量(3台)"></a>安装Hadoop并配置环境变量(3台)</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">上传至服务器并且解压更改名称</span></span><br><span class="line">tar -zxvf hadoop-3.1.3.tar.gz</span><br><span class="line">mv hadoop-3.1.3 hadoop</span><br><span class="line">rm -rf hadoop-3.1.3.tar.gz</span><br></pre></td></tr></table></figure>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">查看是否可用</span></span><br><span class="line">/opt/hadoop/bin/hadoop version</span><br></pre></td></tr></table></figure>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">编辑profile文件</span></span><br><span class="line">vim /etc/profile</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">增加hadoop环境变量</span></span><br><span class="line">export HADOOP_HOME=/opt/hadoop</span><br><span class="line">export PATH=$PATH:$HADOOP_HOME/bin:$HADOOP_HOME/sbin</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">使配置文件生效</span></span><br><span class="line">source /etc/profile</span><br></pre></td></tr></table></figure>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hadoop version</span><br></pre></td></tr></table></figure>

<h2 id="修改环境变量-3台"><a href="#修改环境变量-3台" class="headerlink" title="修改环境变量(3台)"></a>修改环境变量(3台)</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">编辑配置文件</span></span><br><span class="line">vim /etc/profile</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">添加环境变量</span></span><br><span class="line">export HDFS_NAMENODE_USER=root</span><br><span class="line">export HDFS_DATANODE_USER=root</span><br><span class="line">export HDFS_SECONDARYNAMENODE_USER=root</span><br><span class="line">export YARN_RESOURCEMANAGER_USER=root</span><br><span class="line">export YARN_NODEMANAGER_USER=root</span><br><span class="line"></span><br><span class="line">export HADOOP_COMMON_LIB_NATIVE_DIR=$HADOOP_HOME/lib/native </span><br><span class="line">export HADOOP_OPTS=&quot;-Djava.library.path=$HADOOP_HOME/lib&quot; </span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">使配置文件生效</span></span><br><span class="line">source /etc/profile</span><br></pre></td></tr></table></figure>

<h2 id="修改配置文件-3台"><a href="#修改配置文件-3台" class="headerlink" title="修改配置文件(3台)"></a>修改配置文件(3台)</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">hadoop 配置文件都在hadoop 安装目录下的 /etc/hadoop 中</span></span><br><span class="line">cd /opt/hadoop/etc/hadoop</span><br></pre></td></tr></table></figure>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">vim hadoop-env.sh</span><br><span class="line"></span><br><span class="line">export JAVA_HOME=/opt/jdk8</span><br></pre></td></tr></table></figure>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">vim core-site.xml</span><br><span class="line"></span><br><span class="line">&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;</span><br><span class="line">&lt;?xml-stylesheet type=&quot;text/xsl&quot; href=&quot;configuration.xsl&quot;?&gt;</span><br><span class="line">&lt;configuration&gt;</span><br><span class="line">    &lt;!--指定namenode的地址--&gt;</span><br><span class="line">    &lt;property&gt;</span><br><span class="line">        &lt;name&gt;fs.defaultFS&lt;/name&gt;</span><br><span class="line">        &lt;value&gt;hdfs://hadoop1:8020&lt;/value&gt;</span><br><span class="line">    &lt;/property&gt;</span><br><span class="line">    &lt;!-- 指定 Hadoop 运行时产生文件的存储目录 --&gt;</span><br><span class="line">    &lt;property&gt;</span><br><span class="line">        &lt;name&gt;hadoop.tmp.dir&lt;/name&gt;</span><br><span class="line">        &lt;value&gt;/opt/hadoop/data&lt;/value&gt;</span><br><span class="line">    &lt;/property&gt;</span><br><span class="line">&lt;/configuration&gt;</span><br></pre></td></tr></table></figure>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">vim hdfs-site.xml</span><br><span class="line"></span><br><span class="line">&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;</span><br><span class="line">&lt;?xml-stylesheet type=&quot;text/xsl&quot; href=&quot;configuration.xsl&quot;?&gt;</span><br><span class="line">&lt;configuration&gt;</span><br><span class="line">    &lt;!--nn web端访问地址--&gt;</span><br><span class="line">    &lt;property&gt;</span><br><span class="line">        &lt;name&gt;dfs.namenode.http-address&lt;/name&gt;</span><br><span class="line">        &lt;value&gt;hadoop1:9870&lt;/value&gt;</span><br><span class="line">    &lt;/property&gt;</span><br><span class="line">    &lt;!-- 2nn web端访问地址 --&gt;</span><br><span class="line">    &lt;property&gt;</span><br><span class="line">        &lt;name&gt;dfs.namenode.secondary.http-address&lt;/name&gt;</span><br><span class="line">        &lt;value&gt;hadoop3:9868&lt;/value&gt;</span><br><span class="line">    &lt;/property&gt;</span><br><span class="line">&lt;/configuration&gt;</span><br></pre></td></tr></table></figure>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">vim yarn-site.xml</span><br><span class="line"></span><br><span class="line">&lt;?xml version=&quot;1.0&quot;?&gt;</span><br><span class="line">&lt;configuration&gt;</span><br><span class="line">    &lt;!-- 指定 MR 走shuffle --&gt;</span><br><span class="line">    &lt;property&gt;</span><br><span class="line">        &lt;name&gt;yarn.nodemanager.aux-services&lt;/name&gt;</span><br><span class="line">        &lt;value&gt;mapreduce_shuffle&lt;/value&gt;</span><br><span class="line">    &lt;/property&gt;</span><br><span class="line">    &lt;!-- 指定 YARN 的 ResourceManager 的地址 --&gt;</span><br><span class="line">    &lt;property&gt;</span><br><span class="line">        &lt;name&gt;yarn.resourcemanager.hostname&lt;/name&gt;</span><br><span class="line">        &lt;value&gt;hadoop2&lt;/value&gt;</span><br><span class="line">    &lt;/property&gt;</span><br><span class="line">&lt;/configuration&gt;</span><br></pre></td></tr></table></figure>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">vim mapred-site.xml</span><br><span class="line"></span><br><span class="line">&lt;?xml version=&quot;1.0&quot;?&gt;</span><br><span class="line">&lt;?xml-stylesheet type=&quot;text/xsl&quot; href=&quot;configuration.xsl&quot;?&gt;</span><br><span class="line">&lt;configuration&gt;</span><br><span class="line">    &lt;!-- 指定 MR 运行在 Yarn 上 --&gt;</span><br><span class="line">    &lt;property&gt;</span><br><span class="line">        &lt;name&gt;mapreduce.framework.name&lt;/name&gt;</span><br><span class="line">        &lt;value&gt;yarn&lt;/value&gt;</span><br><span class="line">    &lt;/property&gt;</span><br><span class="line">&lt;/configuration&gt;</span><br></pre></td></tr></table></figure>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">vim workers</span><br><span class="line"></span><br><span class="line">hadoop1</span><br><span class="line">hadoop2</span><br><span class="line">hadoop3</span><br></pre></td></tr></table></figure>

<h2 id="格式化集群文件系统-3台"><a href="#格式化集群文件系统-3台" class="headerlink" title="格式化集群文件系统(3台)"></a>格式化集群文件系统(3台)</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hdfs namenode -format</span><br></pre></td></tr></table></figure>

<h2 id="启动分布式集群-3台"><a href="#启动分布式集群-3台" class="headerlink" title="启动分布式集群(3台)"></a>启动分布式集群(3台)</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">start-all.sh</span><br><span class="line">jps   # 查看进程</span><br></pre></td></tr></table></figure>
<img src="/2022/11/12/Hadoop-%C2%A9-pepsi-wyl/1663667031629-0ff30139-f400-47bf-ac71-39e25f3ea064.png" class=""> 

<h2 id="Web管理界面（关闭防火墙或者放行端口）-1"><a href="#Web管理界面（关闭防火墙或者放行端口）-1" class="headerlink" title="Web管理界面（关闭防火墙或者放行端口）"></a>Web管理界面（关闭防火墙或者放行端口）</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">hadoop1的IP NameNode</span><br><span class="line">http://192.168.131.145:9870</span><br></pre></td></tr></table></figure>
<img src="/2022/11/12/Hadoop-%C2%A9-pepsi-wyl/1663667968980-4500cc37-383b-4b43-b3ad-e688914d9e48.png" class=""> 
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">hadoop2的IP ResourceManager</span><br><span class="line">http://192.168.131.146:8088</span><br></pre></td></tr></table></figure>
<img src="/2022/11/12/Hadoop-%C2%A9-pepsi-wyl/1663668001933-91605b47-88b7-4104-ac16-4feb8b525aa4.png" class=""> 

<h2 id="关闭分布式集群-3台"><a href="#关闭分布式集群-3台" class="headerlink" title="关闭分布式集群(3台)"></a>关闭分布式集群(3台)</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">stop-all.sh</span><br></pre></td></tr></table></figure>

<h1 id="文件的操作综合应用"><a href="#文件的操作综合应用" class="headerlink" title="文件的操作综合应用"></a>文件的操作综合应用</h1><h2 id="命令行操作"><a href="#命令行操作" class="headerlink" title="命令行操作"></a>命令行操作</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 列出HDFS文件</span></span><br><span class="line">hadoop fs -<span class="built_in">ls</span> 文件夹的路径 </span><br><span class="line">hadoop fs -<span class="built_in">ls</span> /</span><br></pre></td></tr></table></figure>
<img src="/2022/11/12/Hadoop-%C2%A9-pepsi-wyl/1664439577142-d9498b98-34c7-49f8-bb3e-080eef05818c.png" class=""> 
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 在HDFS中创建文件夹</span></span><br><span class="line">hadoop fs -<span class="built_in">mkdir</span> 文件夹名   </span><br><span class="line">hadoop fs -<span class="built_in">mkdir</span> /testmkdir</span><br></pre></td></tr></table></figure>
<img src="/2022/11/12/Hadoop-%C2%A9-pepsi-wyl/1664439464457-a5459725-9b01-49e0-8334-29b4ba1aab06.png" class=""> 
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 删除HDFS中的文件或文件夹</span></span><br><span class="line">hadoop fs -<span class="built_in">rm</span> -r 文件夹名/文件名</span><br><span class="line">hadoop fs -<span class="built_in">rm</span> -r /testmkdir  </span><br></pre></td></tr></table></figure>
<img src="/2022/11/12/Hadoop-%C2%A9-pepsi-wyl/1664439596814-da571959-f0aa-461c-87f7-1735c712b427.png" class=""> 
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 上传文件到HDFS</span></span><br><span class="line">hadoop fs –put ~/file /   ======&gt; ~/file:本地文件 /:HDFS文件路径</span><br><span class="line">hadoop fs -put t.c    /</span><br></pre></td></tr></table></figure>
<img src="/2022/11/12/Hadoop-%C2%A9-pepsi-wyl/1664441108215-1f3ab21c-bd81-4d74-9498-c91671922ff4.png" class=""> 
<img src="/2022/11/12/Hadoop-%C2%A9-pepsi-wyl/1664441141955-7618e4fc-f47d-44e2-9b28-17ccd856f2bd.png" class=""> 
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 查看HDFS下的某个文件</span></span><br><span class="line">hadoop fs –<span class="built_in">cat</span> 文件路径</span><br><span class="line">hadoop fs -<span class="built_in">cat</span> /t.c</span><br></pre></td></tr></table></figure>
<img src="/2022/11/12/Hadoop-%C2%A9-pepsi-wyl/1664441125309-a3d00af8-9701-462a-a1db-4a0415641c6f.png" class=""> 
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 将HDFS中的文件复制到本地系统中</span></span><br><span class="line">hadoop fs -get  HDFS中的文件名本地系统中的文件名 本地存放地址</span><br><span class="line">hadoop fs -get /t.c /</span><br></pre></td></tr></table></figure>
<img src="/2022/11/12/Hadoop-%C2%A9-pepsi-wyl/1664441331730-5c0a7863-bb3e-487c-ac0f-93aec9294ad9.png" class=""> 
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 修改HDFS中的文件和文件夹的名称</span></span><br><span class="line">hadoop fs  -<span class="built_in">mv</span> /原HDFS中的文件名  /修改后的HDFS中的文件名</span><br><span class="line">hadoop fs  -<span class="built_in">mv</span> /t.c  /t1.c</span><br></pre></td></tr></table></figure>
<img src="/2022/11/12/Hadoop-%C2%A9-pepsi-wyl/1664441529518-4edc7cf8-e282-4054-bd55-94813c4cd57d.png" class=""> 

<h2 id="HDFS-API编程"><a href="#HDFS-API编程" class="headerlink" title="HDFS API编程"></a>HDFS API编程</h2><p>代码链接 <a target="_blank" rel="noopener" href="https://github.com/pepsi-wyl/HDFS_API">https://github.com/pepsi-wyl/HDFS_API</a><br><strong>BUG</strong> <a target="_blank" rel="noopener" href="https://www.panziye.com/java/3041.html">解决java.io.FileNotFoundException: java.io.FileNotFoundException: HADOOP_HOME and hadoop.home.dir are unset</a></p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">dependencies</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.hadoop<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>hadoop-common<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">version</span>&gt;</span>3.3.1<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.hadoop<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>hadoop-hdfs<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">version</span>&gt;</span>3.3.1<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.hadoop<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>hadoop-client<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">version</span>&gt;</span>3.3.1<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependencies</span>&gt;</span></span><br></pre></td></tr></table></figure>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">HDFSUtils</span> &#123;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 获取Configuration</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> Configuration <span class="title function_">getConfiguration</span><span class="params">()</span> &#123;</span><br><span class="line">        <span class="type">Configuration</span> <span class="variable">configuration</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Configuration</span>();</span><br><span class="line">        <span class="comment">// 这里指定使用的是HDFS文件系统</span></span><br><span class="line">        configuration.set(<span class="string">&quot;fs.defaultFS&quot;</span>, <span class="string">&quot;hdfs://192.168.131.144:9000&quot;</span>);</span><br><span class="line">        configuration.set(<span class="string">&quot;fs.hdfs.impl&quot;</span>, <span class="string">&quot;org.apache.hadoop.hdfs.DistributedFileSystem&quot;</span>);</span><br><span class="line">        <span class="keyword">return</span> configuration;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 获取FileSystem</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> FileSystem <span class="title function_">getFileSystem</span><span class="params">()</span> <span class="keyword">throws</span> IOException &#123;</span><br><span class="line">        <span class="comment">// 通过如下的方式进行客户端身份的设置</span></span><br><span class="line">        System.setProperty(<span class="string">&quot;HADOOP_USER_NAME&quot;</span>, <span class="string">&quot;root&quot;</span>);</span><br><span class="line">        <span class="comment">// 通过FileSystem的静态方法获取文件系统客户端对象</span></span><br><span class="line">        <span class="type">FileSystem</span> <span class="variable">fileSystem</span> <span class="operator">=</span> <span class="literal">null</span>;</span><br><span class="line">        <span class="keyword">return</span> FileSystem.get(getConfiguration());</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 关闭FileSystem</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">closeFileSystem</span><span class="params">(FileSystem fileSystem)</span> <span class="keyword">throws</span> IOException &#123;</span><br><span class="line">        fileSystem.close();</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 列出HDFS文件</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">ListFiles</span> &#123;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> IOException &#123;</span><br><span class="line">        <span class="type">FileSystem</span> <span class="variable">fileSystem</span> <span class="operator">=</span> HDFSUtils.getFileSystem();</span><br><span class="line">        FileStatus[] statuses = fileSystem.listStatus(<span class="keyword">new</span> <span class="title class_">Path</span>(<span class="string">&quot;/&quot;</span>));</span><br><span class="line">        <span class="keyword">for</span> (FileStatus fileStatus : statuses) &#123;</span><br><span class="line">            <span class="comment">// fileStatus为文件状态存储文件的信息</span></span><br><span class="line">            System.out.println(fileStatus.getPath());</span><br><span class="line">        &#125;</span><br><span class="line">        HDFSUtils.closeFileSystem(fileSystem);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<img src="/2022/11/12/Hadoop-%C2%A9-pepsi-wyl/1664453706943-25cbbc50-0d83-482a-98d6-153e074d89bb.png" class=""> 
<img src="/2022/11/12/Hadoop-%C2%A9-pepsi-wyl/1664453722783-03cf448d-fd95-47b2-a83f-a7a49285d3ab.png" class=""> 
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 创建文件夹</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">Mkdir</span> &#123;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> IOException &#123;</span><br><span class="line">        <span class="type">FileSystem</span> <span class="variable">fileSystem</span> <span class="operator">=</span> HDFSUtils.getFileSystem();</span><br><span class="line">        <span class="type">boolean</span> <span class="variable">isOK</span> <span class="operator">=</span> fileSystem.mkdirs(<span class="keyword">new</span> <span class="title class_">Path</span>(<span class="string">&quot;/javaAPI/&quot;</span>));</span><br><span class="line">        <span class="keyword">if</span> (isOK)</span><br><span class="line">            System.out.printf(<span class="string">&quot;创建文件夹成功&quot;</span>);</span><br><span class="line">        <span class="keyword">else</span></span><br><span class="line">            System.out.printf(<span class="string">&quot;创建文件夹失败&quot;</span>);</span><br><span class="line">        HDFSUtils.closeFileSystem(fileSystem);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<img src="/2022/11/12/Hadoop-%C2%A9-pepsi-wyl/1664453752647-e7d58730-b024-4a07-b26c-c68de5b1cf63.png" class=""> 
<img src="/2022/11/12/Hadoop-%C2%A9-pepsi-wyl/1664453772003-bcdd4904-5a91-4018-9ab3-83394f68416d.png" class=""> 
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 删除文件夹</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">Rmdir</span> &#123;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> IOException &#123;</span><br><span class="line">        <span class="type">FileSystem</span> <span class="variable">fileSystem</span> <span class="operator">=</span> HDFSUtils.getFileSystem();</span><br><span class="line">        <span class="comment">// true为递归删除 false单级目录删除</span></span><br><span class="line">        <span class="type">boolean</span> <span class="variable">isOK</span> <span class="operator">=</span> fileSystem.delete(<span class="keyword">new</span> <span class="title class_">Path</span>(<span class="string">&quot;/javaAPI/&quot;</span>), <span class="literal">false</span>);</span><br><span class="line">        <span class="keyword">if</span> (isOK)</span><br><span class="line">            System.out.printf(<span class="string">&quot;删除文件夹成功&quot;</span>);</span><br><span class="line">        <span class="keyword">else</span></span><br><span class="line">            System.out.printf(<span class="string">&quot;删除文件夹失败&quot;</span>);</span><br><span class="line">        HDFSUtils.closeFileSystem(fileSystem);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<img src="/2022/11/12/Hadoop-%C2%A9-pepsi-wyl/1664453808865-e57580cb-44de-4479-9a5f-a535961df6ce.png" class=""> 
<img src="/2022/11/12/Hadoop-%C2%A9-pepsi-wyl/1664453816837-7649d9aa-6653-454a-a5e2-ced6b240db59.png" class=""> 
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 上传文件</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">Upload</span> &#123;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> IOException &#123;</span><br><span class="line">        <span class="type">FileSystem</span> <span class="variable">fileSystem</span> <span class="operator">=</span> HDFSUtils.getFileSystem();</span><br><span class="line">        <span class="type">Path</span> <span class="variable">localFile</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Path</span>(<span class="string">&quot;G:\\Coding\\java\\HDFS_API\\src\\main\\java\\Utils\\HDFSUtils.java&quot;</span>);</span><br><span class="line">        <span class="type">Path</span> <span class="variable">remoteFile</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Path</span>(<span class="string">&quot;/&quot;</span>);</span><br><span class="line">        fileSystem.copyFromLocalFile(localFile, remoteFile);</span><br><span class="line">        System.out.println(<span class="string">&quot;上传文件成功&quot;</span>);</span><br><span class="line">        HDFSUtils.closeFileSystem(fileSystem);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<img src="/2022/11/12/Hadoop-%C2%A9-pepsi-wyl/1664453849662-5a8b9565-7d29-4600-aaee-c5e45e54d7e1.png" class=""> 
<img src="/2022/11/12/Hadoop-%C2%A9-pepsi-wyl/1664453864273-a459eb28-e3d5-46fb-894f-88f04602d34b.png" class=""> 
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 下载文件</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">Download</span> &#123;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> IOException &#123;</span><br><span class="line">        <span class="type">FileSystem</span> <span class="variable">fileSystem</span> <span class="operator">=</span> HDFSUtils.getFileSystem();</span><br><span class="line">        <span class="type">Path</span> <span class="variable">remoteFile</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Path</span>(<span class="string">&quot;/HDFSUtils.java&quot;</span>);</span><br><span class="line">        <span class="type">Path</span> <span class="variable">localFile</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Path</span>(<span class="string">&quot;G:\\Coding\\java\\HDFS_API\\src&quot;</span>);</span><br><span class="line">        fileSystem.copyToLocalFile(remoteFile, localFile);</span><br><span class="line">        System.out.println(<span class="string">&quot;下载文件成功&quot;</span>);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<img src="/2022/11/12/Hadoop-%C2%A9-pepsi-wyl/1664453912255-7d72dad3-3c10-4ae8-b450-8cf2549a530a.png" class=""> 
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 修改HDFS中的文件和文件夹的名称</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">RenameFile</span> &#123;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> IOException &#123;</span><br><span class="line">        <span class="type">FileSystem</span> <span class="variable">fileSystem</span> <span class="operator">=</span> HDFSUtils.getFileSystem();</span><br><span class="line">        <span class="type">Path</span> <span class="variable">oldPath</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Path</span>(<span class="string">&quot;/HDFSUtils.java&quot;</span>);</span><br><span class="line">        <span class="type">Path</span> <span class="variable">newPath</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Path</span>(<span class="string">&quot;/HDFSUtils_rename.java&quot;</span>);</span><br><span class="line">        <span class="type">boolean</span> <span class="variable">rename</span> <span class="operator">=</span> fileSystem.rename(oldPath, newPath);</span><br><span class="line">        <span class="keyword">if</span> (rename)</span><br><span class="line">            System.out.println(<span class="string">&quot;重命名成功&quot;</span>);</span><br><span class="line">        <span class="keyword">else</span></span><br><span class="line">            System.out.println(<span class="string">&quot;重命名失败&quot;</span>);</span><br><span class="line">        HDFSUtils.closeFileSystem(fileSystem);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<img src="/2022/11/12/Hadoop-%C2%A9-pepsi-wyl/1664453938659-7ba44c6a-ba0e-4000-a259-ffb686379cfa.png" class=""> 
<img src="/2022/11/12/Hadoop-%C2%A9-pepsi-wyl/1664453949575-697dd0a1-37e2-4c9a-bba1-b935355cacd4.png" class=""> 
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 查看HDFS中的文件</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">CatFile</span> &#123;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> IOException &#123;</span><br><span class="line">        <span class="type">FileSystem</span> <span class="variable">fileSystem</span> <span class="operator">=</span> HDFSUtils.getFileSystem();</span><br><span class="line">        <span class="type">FSDataInputStream</span> <span class="variable">in</span> <span class="operator">=</span> fileSystem.open(<span class="keyword">new</span> <span class="title class_">Path</span>(<span class="string">&quot;/HDFSUtils.java&quot;</span>));</span><br><span class="line">        IOUtils.copyBytes(in, System.out, <span class="number">1024</span>);</span><br><span class="line">        HDFSUtils.closeFileSystem(fileSystem);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<img src="/2022/11/12/Hadoop-%C2%A9-pepsi-wyl/1664454028601-33defa24-bffb-4e5c-aaad-e0af4a0e089c.png" class=""> 

<h1 id="MapReduce基础编程"><a href="#MapReduce基础编程" class="headerlink" title="MapReduce基础编程"></a>MapReduce基础编程</h1><h2 id="使用命令行编译打包词频统计程序"><a href="#使用命令行编译打包词频统计程序" class="headerlink" title="使用命令行编译打包词频统计程序"></a>使用命令行编译打包词频统计程序</h2><h3 id="HDFS中创建文件"><a href="#HDFS中创建文件" class="headerlink" title="HDFS中创建文件"></a>HDFS中创建文件</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">wordfile1.txt   </span><br><span class="line">I love Spark</span><br><span class="line">I love Hadoop</span><br><span class="line"></span><br><span class="line">wordfile2.txt.txt    </span><br><span class="line">Hadoop is good</span><br><span class="line">Spark is fast</span><br></pre></td></tr></table></figure>
<p><strong>上传到HDFS中</strong></p>
<img src="/2022/11/12/Hadoop-%C2%A9-pepsi-wyl/1666086361148-02133ef3-7ce4-4be8-baec-3064ab246f96.png" class=""> 

<h3 id="编写源文件"><a href="#编写源文件" class="headerlink" title="编写源文件"></a>编写源文件</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 源文件编写在hadoop的安装路径下</span></span><br><span class="line"><span class="built_in">cd</span> /home/hadoop/hadoop</span><br><span class="line"></span><br><span class="line">vim WordCount.java</span><br></pre></td></tr></table></figure>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> java.io.IOException;</span><br><span class="line"><span class="keyword">import</span> java.util.Iterator;</span><br><span class="line"><span class="keyword">import</span> java.util.StringTokenizer;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.conf.Configuration;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.fs.Path;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.io.IntWritable;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.io.Text;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.Job;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.Mapper;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.Reducer;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.lib.input.FileInputFormat;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.lib.output.FileOutputFormat;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.util.GenericOptionsParser;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@author</span> by pepsi-wyl</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@date</span> 2022-10-18 16:44</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">WordCount</span> &#123;</span><br><span class="line">    <span class="keyword">public</span> <span class="title function_">WordCount</span><span class="params">()</span> &#123;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> Exception &#123;</span><br><span class="line">        <span class="type">Configuration</span> <span class="variable">conf</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Configuration</span>();</span><br><span class="line">        String[] otherArgs = (<span class="keyword">new</span> <span class="title class_">GenericOptionsParser</span>(conf, args)).getRemainingArgs();</span><br><span class="line">        <span class="keyword">if</span> (otherArgs.length &lt; <span class="number">2</span>) &#123;</span><br><span class="line">            System.err.println(<span class="string">&quot;Usage: wordcount &lt;in&gt; [&lt;in&gt;...] &lt;out&gt;&quot;</span>);</span><br><span class="line">            System.exit(<span class="number">2</span>);</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="type">Job</span> <span class="variable">job</span> <span class="operator">=</span> Job.getInstance(conf, <span class="string">&quot;word count&quot;</span>);</span><br><span class="line">        job.setJarByClass(WordCount.class);</span><br><span class="line">        job.setMapperClass(WordCount.TokenizerMapper.class);</span><br><span class="line">        job.setCombinerClass(WordCount.IntSumReducer.class);</span><br><span class="line">        job.setReducerClass(WordCount.IntSumReducer.class);</span><br><span class="line">        job.setOutputKeyClass(Text.class);</span><br><span class="line">        job.setOutputValueClass(IntWritable.class);</span><br><span class="line">        <span class="keyword">for</span> (<span class="type">int</span> <span class="variable">i</span> <span class="operator">=</span> <span class="number">0</span>; i &lt; otherArgs.length - <span class="number">1</span>; ++i) &#123;</span><br><span class="line">            FileInputFormat.addInputPath(job, <span class="keyword">new</span> <span class="title class_">Path</span>(otherArgs[i]));</span><br><span class="line">        &#125;</span><br><span class="line">        FileOutputFormat.setOutputPath(job, <span class="keyword">new</span> <span class="title class_">Path</span>(otherArgs[otherArgs.length - <span class="number">1</span>]));</span><br><span class="line">        System.exit(job.waitForCompletion(<span class="literal">true</span>) ? <span class="number">0</span> : <span class="number">1</span>);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">class</span> <span class="title class_">TokenizerMapper</span> <span class="keyword">extends</span> <span class="title class_">Mapper</span>&lt;Object, Text, Text, IntWritable&gt; &#123;</span><br><span class="line">        <span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> <span class="type">IntWritable</span> <span class="variable">one</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">IntWritable</span>(<span class="number">1</span>);</span><br><span class="line">        <span class="keyword">private</span> <span class="type">Text</span> <span class="variable">word</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Text</span>();</span><br><span class="line"></span><br><span class="line">        <span class="keyword">public</span> <span class="title function_">TokenizerMapper</span><span class="params">()</span> &#123;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">map</span><span class="params">(Object key, Text value, Mapper&lt;Object, Text, Text, IntWritable&gt;.Context context)</span> <span class="keyword">throws</span> IOException, InterruptedException &#123;</span><br><span class="line">            <span class="type">StringTokenizer</span> <span class="variable">itr</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">StringTokenizer</span>(value.toString());</span><br><span class="line">            <span class="keyword">while</span> (itr.hasMoreTokens()) &#123;</span><br><span class="line">                <span class="built_in">this</span>.word.set(itr.nextToken());</span><br><span class="line">                context.write(<span class="built_in">this</span>.word, one);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">class</span> <span class="title class_">IntSumReducer</span> <span class="keyword">extends</span> <span class="title class_">Reducer</span>&lt;Text, IntWritable, Text, IntWritable&gt; &#123;</span><br><span class="line">        <span class="keyword">private</span> <span class="type">IntWritable</span> <span class="variable">result</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">IntWritable</span>();</span><br><span class="line"></span><br><span class="line">        <span class="keyword">public</span> <span class="title function_">IntSumReducer</span><span class="params">()</span> &#123;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">reduce</span><span class="params">(Text key, Iterable&lt;IntWritable&gt; values, Reducer&lt;Text, IntWritable, Text, IntWritable&gt;.Context context)</span> <span class="keyword">throws</span> IOException, InterruptedException &#123;</span><br><span class="line">            <span class="type">int</span> <span class="variable">sum</span> <span class="operator">=</span> <span class="number">0</span>;</span><br><span class="line">            IntWritable val;</span><br><span class="line">            <span class="keyword">for</span> (<span class="type">Iterator</span> <span class="variable">i$</span> <span class="operator">=</span> values.iterator(); i$.hasNext(); sum += val.get()) &#123;</span><br><span class="line">                val = (IntWritable) i$.next();</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="built_in">this</span>.result.set(sum);</span><br><span class="line">            context.write(key, <span class="built_in">this</span>.result);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h3 id="编译打包运行"><a href="#编译打包运行" class="headerlink" title="编译打包运行"></a>编译打包运行</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 在hadoop的安装路径下操作</span></span><br><span class="line"><span class="built_in">cd</span> /home/hadoop/hadoop</span><br><span class="line"></span><br><span class="line"><span class="comment"># javac编译程序可以找到Hadoop相关的JAR包</span></span><br><span class="line"><span class="built_in">export</span> CLASSPATH=<span class="string">&quot;/home/hadoop/hadoop/share/hadoop/common/hadoop-common-3.3.0.jar:/home/hadoop/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-core-3.3.0.jar:/home/hadoop/hadoop/share/hadoop/common/lib/commons-cli-1.2.jar:<span class="variable">$CLASSPATH</span>&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 编译程序</span></span><br><span class="line">javac WordCount.java</span><br><span class="line"></span><br><span class="line"><span class="comment"># 将Java的3个.class可执行文件打包并命名为WordCount.jar</span></span><br><span class="line">jar -cvf WordCount.jar *.class    </span><br><span class="line"></span><br><span class="line"><span class="comment"># 运行jar包</span></span><br><span class="line">./bin/hadoop jar WordCount.jar WordCount input output</span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看结果</span></span><br><span class="line">./bin/hadoop fs -<span class="built_in">cat</span> output/*</span><br></pre></td></tr></table></figure>

<p><strong>编译</strong></p>
<img src="/2022/11/12/Hadoop-%C2%A9-pepsi-wyl/1666086755717-463841a2-4f8b-4173-b835-e7f85e3c1a63.png" class=""> 
<p><strong>打包</strong></p>
<img src="/2022/11/12/Hadoop-%C2%A9-pepsi-wyl/1666086735222-1ceb8c6c-1689-40c0-85ac-7c0ecd82cd38.png" class=""> 
<p><strong>运行</strong></p>
<img src="/2022/11/12/Hadoop-%C2%A9-pepsi-wyl/1666086674036-256e194b-db5f-43a3-a385-a1b4a139df87.png" class=""> 
<p><strong>查看结果</strong></p>
<img src="/2022/11/12/Hadoop-%C2%A9-pepsi-wyl/1666086650756-c5ce2cc6-92ca-4c6c-8f5c-26de0979cf65.png" class=""> 

<h3 id="排错"><a href="#排错" class="headerlink" title="排错"></a>排错</h3><p>Hadoop：找不到或无法加载主类org.apache.hadoop.mapreduce.v2.app.MRAppMaster<br /><a target="_blank" rel="noopener" href="https://blog.csdn.net/lianghecai52171314/article/details/103231176">https://blog.csdn.net/lianghecai52171314/article/details/103231176</a></p>
<h2 id="使用Idea编译运行词频统计程序"><a href="#使用Idea编译运行词频统计程序" class="headerlink" title="使用Idea编译运行词频统计程序"></a>使用Idea编译运行词频统计程序</h2><h3 id="HDFS中创建文件-1"><a href="#HDFS中创建文件-1" class="headerlink" title="HDFS中创建文件"></a>HDFS中创建文件</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">wordfile1.txt   </span><br><span class="line">I love Spark</span><br><span class="line">I love Hadoop</span><br><span class="line"></span><br><span class="line">wordfile2.txt.txt    </span><br><span class="line">Hadoop is good</span><br><span class="line">Spark is fast</span><br></pre></td></tr></table></figure>
<p><strong>上传到HDFS中</strong></p>
<img src="/2022/11/12/Hadoop-%C2%A9-pepsi-wyl/1666086361148-02133ef3-7ce4-4be8-baec-3064ab246f96.png" class=""> 

<h3 id="maven工程"><a href="#maven工程" class="headerlink" title="maven工程"></a>maven工程</h3><h4 id="创建工程"><a href="#创建工程" class="headerlink" title="创建工程"></a>创建工程</h4><img src="/2022/11/12/Hadoop-%C2%A9-pepsi-wyl/1666092766611-2532f20d-08f2-452b-aa32-70a00c89efcb.png" class=""> 

<h4 id="导入依赖"><a href="#导入依赖" class="headerlink" title="导入依赖"></a>导入依赖</h4><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">dependencies</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.hadoop<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>hadoop-common<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">version</span>&gt;</span>3.3.1<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.hadoop<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>hadoop-hdfs<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">version</span>&gt;</span>3.3.1<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.hadoop<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>hadoop-client<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">version</span>&gt;</span>3.3.1<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependencies</span>&gt;</span></span><br></pre></td></tr></table></figure>

<h4 id="编写源码"><a href="#编写源码" class="headerlink" title="编写源码"></a>编写源码</h4><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> org.apache.hadoop.conf.Configuration;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.fs.Path;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.io.IntWritable;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.io.Text;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.Job;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.Mapper;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.Reducer;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.lib.input.FileInputFormat;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.lib.output.FileOutputFormat;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.util.GenericOptionsParser;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.io.IOException;</span><br><span class="line"><span class="keyword">import</span> java.util.Iterator;</span><br><span class="line"><span class="keyword">import</span> java.util.StringTokenizer;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@author</span> by pepsi-wyl</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@date</span> 2022-10-18 16:44</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">WordCount</span> &#123;</span><br><span class="line">    <span class="keyword">public</span> <span class="title function_">WordCount</span><span class="params">()</span> &#123;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> Exception &#123;</span><br><span class="line">        <span class="type">Configuration</span> <span class="variable">conf</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Configuration</span>();</span><br><span class="line">        String[] otherArgs = (<span class="keyword">new</span> <span class="title class_">GenericOptionsParser</span>(conf, args)).getRemainingArgs();</span><br><span class="line">        <span class="keyword">if</span> (otherArgs.length &lt; <span class="number">2</span>) &#123;</span><br><span class="line">            System.err.println(<span class="string">&quot;Usage: wordcount &lt;in&gt; [&lt;in&gt;...] &lt;out&gt;&quot;</span>);</span><br><span class="line">            System.exit(<span class="number">2</span>);</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="type">Job</span> <span class="variable">job</span> <span class="operator">=</span> Job.getInstance(conf, <span class="string">&quot;word count&quot;</span>);</span><br><span class="line">        job.setJarByClass(WordCount.class);</span><br><span class="line">        job.setMapperClass(TokenizerMapper.class);</span><br><span class="line">        job.setCombinerClass(IntSumReducer.class);</span><br><span class="line">        job.setReducerClass(IntSumReducer.class);</span><br><span class="line">        job.setOutputKeyClass(Text.class);</span><br><span class="line">        job.setOutputValueClass(IntWritable.class);</span><br><span class="line">        <span class="keyword">for</span> (<span class="type">int</span> <span class="variable">i</span> <span class="operator">=</span> <span class="number">0</span>; i &lt; otherArgs.length - <span class="number">1</span>; ++i) &#123;</span><br><span class="line">            FileInputFormat.addInputPath(job, <span class="keyword">new</span> <span class="title class_">Path</span>(otherArgs[i]));</span><br><span class="line">        &#125;</span><br><span class="line">        FileOutputFormat.setOutputPath(job, <span class="keyword">new</span> <span class="title class_">Path</span>(otherArgs[otherArgs.length - <span class="number">1</span>]));</span><br><span class="line">        System.exit(job.waitForCompletion(<span class="literal">true</span>) ? <span class="number">0</span> : <span class="number">1</span>);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">class</span> <span class="title class_">TokenizerMapper</span> <span class="keyword">extends</span> <span class="title class_">Mapper</span>&lt;Object, Text, Text, IntWritable&gt; &#123;</span><br><span class="line">        <span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> <span class="type">IntWritable</span> <span class="variable">one</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">IntWritable</span>(<span class="number">1</span>);</span><br><span class="line">        <span class="keyword">private</span> <span class="type">Text</span> <span class="variable">word</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Text</span>();</span><br><span class="line"></span><br><span class="line">        <span class="keyword">public</span> <span class="title function_">TokenizerMapper</span><span class="params">()</span> &#123;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">map</span><span class="params">(Object key, Text value, Mapper&lt;Object, Text, Text, IntWritable&gt;.Context context)</span> <span class="keyword">throws</span> IOException, InterruptedException &#123;</span><br><span class="line">            <span class="type">StringTokenizer</span> <span class="variable">itr</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">StringTokenizer</span>(value.toString());</span><br><span class="line">            <span class="keyword">while</span> (itr.hasMoreTokens()) &#123;</span><br><span class="line">                <span class="built_in">this</span>.word.set(itr.nextToken());</span><br><span class="line">                context.write(<span class="built_in">this</span>.word, one);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">class</span> <span class="title class_">IntSumReducer</span> <span class="keyword">extends</span> <span class="title class_">Reducer</span>&lt;Text, IntWritable, Text, IntWritable&gt; &#123;</span><br><span class="line">        <span class="keyword">private</span> <span class="type">IntWritable</span> <span class="variable">result</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">IntWritable</span>();</span><br><span class="line"></span><br><span class="line">        <span class="keyword">public</span> <span class="title function_">IntSumReducer</span><span class="params">()</span> &#123;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">reduce</span><span class="params">(Text key, Iterable&lt;IntWritable&gt; values, Reducer&lt;Text, IntWritable, Text, IntWritable&gt;.Context context)</span> <span class="keyword">throws</span> IOException, InterruptedException &#123;</span><br><span class="line">            <span class="type">int</span> <span class="variable">sum</span> <span class="operator">=</span> <span class="number">0</span>;</span><br><span class="line">            IntWritable val;</span><br><span class="line">            <span class="keyword">for</span> (<span class="type">Iterator</span> <span class="variable">i$</span> <span class="operator">=</span> values.iterator(); i$.hasNext(); sum += val.get()) &#123;</span><br><span class="line">                val = (IntWritable) i$.next();</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="built_in">this</span>.result.set(sum);</span><br><span class="line">            context.write(key, <span class="built_in">this</span>.result);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h4 id="打包"><a href="#打包" class="headerlink" title="打包"></a>打包</h4><img src="/2022/11/12/Hadoop-%C2%A9-pepsi-wyl/1666093874063-e79c44be-e14b-4aae-bcab-f4c1a0ea29c1.png" class=""> 
<img src="/2022/11/12/Hadoop-%C2%A9-pepsi-wyl/1666094025109-e6fef8eb-315e-4ee6-a7d7-772b6681d864.png" class=""> 

<h3 id="上传服务器运行"><a href="#上传服务器运行" class="headerlink" title="上传服务器运行"></a>上传服务器运行</h3><img src="/2022/11/12/Hadoop-%C2%A9-pepsi-wyl/1666094119014-befca265-3725-4672-9c7b-5c30da0b1c5b.png" class=""> 
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 运行jar包</span></span><br><span class="line">./bin/hadoop jar WordCount-1.0-SNAPSHOT.jar WordCount input output</span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看结果</span></span><br><span class="line">./bin/hadoop fs -<span class="built_in">cat</span> output/*</span><br></pre></td></tr></table></figure>

<p><strong>运行</strong></p>
<img src="/2022/11/12/Hadoop-%C2%A9-pepsi-wyl/1666094258647-504a15bf-f744-4c2a-a3a2-a81cdf16f1d7.png" class=""> 
<p><strong>查看结果</strong></p>
<img src="/2022/11/12/Hadoop-%C2%A9-pepsi-wyl/1666094282090-fb888bf8-50b3-47a1-b6dc-6bbcf697602b.png" class=""> 

<h1 id="HBase基本使用"><a href="#HBase基本使用" class="headerlink" title="HBase基本使用"></a>HBase基本使用</h1><h2 id="安装"><a href="#安装" class="headerlink" title="安装"></a>安装</h2><h3 id="下载和安装"><a href="#下载和安装" class="headerlink" title="下载和安装"></a>下载和安装</h3><h4 id="版本对应关系"><a href="#版本对应关系" class="headerlink" title="版本对应关系"></a>版本对应关系</h4><p>:::tips<br>HBase版本2.2.2 <strong>(注意兼容性)</strong><br /><a target="_blank" rel="noopener" href="https://hbase.apache.org/book.html#hadoop">https://hbase.apache.org/book.html#hadoop</a><br>:::</p>
<h4 id="下载和解压"><a href="#下载和解压" class="headerlink" title="下载和解压"></a>下载和解压</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 下载</span></span><br><span class="line">wget https://archive.apache.org/dist/hbase/2.2.2/hbase-2.2.2-bin.tar.gz</span><br><span class="line"></span><br><span class="line"><span class="comment"># 解压</span></span><br><span class="line">tar -zxvf hbase-2.2.7-bin.tar.gz</span><br><span class="line"></span><br><span class="line"><span class="comment"># 删除源码包</span></span><br><span class="line"><span class="built_in">rm</span> -rf hbase-2.2.7-bin.tar.gz</span><br><span class="line"></span><br><span class="line"><span class="comment"># 重命名</span></span><br><span class="line"><span class="built_in">mv</span> hbase-2.2.7 hbase</span><br></pre></td></tr></table></figure>

<h4 id="配置环境变量"><a href="#配置环境变量" class="headerlink" title="配置环境变量"></a>配置环境变量</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 编辑配置文件</span></span><br><span class="line">vim /etc/profile </span><br><span class="line"></span><br><span class="line"><span class="built_in">export</span> HBASE_HOME=/home/hadoop/hbase</span><br><span class="line"><span class="built_in">export</span> PATH=<span class="variable">$PATH</span>:<span class="variable">$HBASE_HOME</span>/bin:/<span class="variable">$HBASE_HOME</span>/sbin</span><br><span class="line"></span><br><span class="line"><span class="comment"># 使配置文件生效</span></span><br><span class="line"><span class="built_in">source</span> /etc/profile</span><br></pre></td></tr></table></figure>
<img src="/2022/11/12/Hadoop-%C2%A9-pepsi-wyl/1666833633192-1e6f1219-18b6-4cca-b688-1db5a92972d5.png" class=""> 

<h4 id="查看HBase版本信息"><a href="#查看HBase版本信息" class="headerlink" title="查看HBase版本信息"></a>查看HBase版本信息</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 查看版本信息</span></span><br><span class="line">hbase version</span><br></pre></td></tr></table></figure>
<img src="/2022/11/12/Hadoop-%C2%A9-pepsi-wyl/1666833256300-93192e20-dcc3-4c5e-ba5e-56524408e4e0.png" class=""> 

<h3 id="配置"><a href="#配置" class="headerlink" title="配置"></a>配置</h3><h4 id="配置hbase-env-sh"><a href="#配置hbase-env-sh" class="headerlink" title="配置hbase-env.sh"></a>配置hbase-env.sh</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">vim /home/hadoop/hbase/conf/hbase-env.sh</span><br><span class="line"></span><br><span class="line"><span class="built_in">export</span> JAVA_HOME=/home/hadoop/jdk8</span><br><span class="line"><span class="built_in">export</span> HBASE_CLASSPATH=/home/hadoop/hbase/conf</span><br><span class="line"><span class="built_in">export</span> HBASE_MANAGES_ZK=<span class="literal">true</span></span><br></pre></td></tr></table></figure>
<img src="/2022/11/12/Hadoop-%C2%A9-pepsi-wyl/1666833711166-4714d08e-e817-4898-a974-a8f24b211206.png" class=""> 

<h4 id="配置hbase-site-xml"><a href="#配置hbase-site-xml" class="headerlink" title="配置hbase-site.xml"></a>配置hbase-site.xml</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">vim /home/hadoop/hbase/conf/hbase-site.xml</span><br></pre></td></tr></table></figure>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&lt;?xml version=<span class="string">&quot;1.0&quot;</span>?&gt;</span></span><br><span class="line"><span class="meta">&lt;?xml-stylesheet type=<span class="string">&quot;text/xsl&quot;</span> href=<span class="string">&quot;configuration.xsl&quot;</span>?&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>hbase.rootdir<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">				<span class="comment">&lt;!--IP为自己的虚机IP--&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>hdfs://192.168.131.144:9000/hbase<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>hbase.cluster.distributed<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>true<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>hbase.unsafe.stream.capability.enforce<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>false<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br></pre></td></tr></table></figure>
<img src="/2022/11/12/Hadoop-%C2%A9-pepsi-wyl/1666785067910-12967934-9e4a-43f3-b33a-e22fdb44da32.png" class=""> 

<h3 id="启动和停止"><a href="#启动和停止" class="headerlink" title="启动和停止"></a>启动和停止</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 首先启动Hadoop</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 启动HBase</span></span><br><span class="line">/home/hadoop/hbase/bin/start-hbase.sh</span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看启动的进程</span></span><br><span class="line">jps</span><br></pre></td></tr></table></figure>
<img src="/2022/11/12/Hadoop-%C2%A9-pepsi-wyl/1666833437687-86f0490f-1a84-427c-abb5-efcad7c0bcd6.png" class=""> 
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 停止HBase</span></span><br><span class="line">/home/hadoop/hbase/bin/hbase-daemon.sh stop master</span><br><span class="line">/home/hadoop/hbase/bin/stop-hbase.sh</span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看启动的进程</span></span><br><span class="line">jps</span><br></pre></td></tr></table></figure>
<img src="/2022/11/12/Hadoop-%C2%A9-pepsi-wyl/1666786886054-3757a29a-9bba-458e-b295-abc3745ebd10.png" class=""> 
<img src="/2022/11/12/Hadoop-%C2%A9-pepsi-wyl/1666786886913-86709fe7-5da4-403c-8db1-bc0513b738bf.png" class=""> 

<h2 id="Shell命令"><a href="#Shell命令" class="headerlink" title="Shell命令"></a>Shell命令</h2><h3 id="启动"><a href="#启动" class="headerlink" title="启动"></a>启动</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 启动HBase Shell</span></span><br><span class="line">/home/hadoop/hbase/bin/hbase shell</span><br></pre></td></tr></table></figure>
<img src="/2022/11/12/Hadoop-%C2%A9-pepsi-wyl/1666833479444-785641b0-1da7-482f-b3de-1d1c33683a24.png" class=""> 

<h3 id="创建表"><a href="#创建表" class="headerlink" title="创建表"></a>创建表</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 创建表</span></span><br><span class="line">create <span class="string">&#x27;student&#x27;</span>,<span class="string">&#x27;Sname&#x27;</span>,<span class="string">&#x27;Ssex&#x27;</span>,<span class="string">&#x27;Sage&#x27;</span>,<span class="string">&#x27;Sdept&#x27;</span>,<span class="string">&#x27;course&#x27;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看表信息</span></span><br><span class="line">describe <span class="string">&#x27;student&#x27;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看表</span></span><br><span class="line">list</span><br></pre></td></tr></table></figure>
<img src="/2022/11/12/Hadoop-%C2%A9-pepsi-wyl/1667009441071-8bdc163f-e0ac-456a-9b6e-70d619cf3480.png" class=""> 
<img src="/2022/11/12/Hadoop-%C2%A9-pepsi-wyl/1667009462736-9ec35cce-0808-4384-8414-38825de33613.png" class=""> 
<img src="/2022/11/12/Hadoop-%C2%A9-pepsi-wyl/1667009474325-56ac4ad1-b5e5-4894-91a1-5c74f2c21b80.png" class=""> 

<h3 id="删除表"><a href="#删除表" class="headerlink" title="删除表"></a>删除表</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 删除表  让表不可用</span></span><br><span class="line"><span class="built_in">disable</span> <span class="string">&#x27;student&#x27;</span> </span><br><span class="line"></span><br><span class="line"><span class="comment"># 删除表  让表不可用</span></span><br><span class="line">drop <span class="string">&#x27;student&#x27;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看表</span></span><br><span class="line">list </span><br></pre></td></tr></table></figure>
<img src="/2022/11/12/Hadoop-%C2%A9-pepsi-wyl/1667009518411-3fbf382d-a514-4a7e-92e9-65ee3d6d6f74.png" class=""> 

<h3 id="插入数据"><a href="#插入数据" class="headerlink" title="插入数据"></a>插入数据</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 插入数据</span></span><br><span class="line">put <span class="string">&#x27;student&#x27;</span>,<span class="string">&#x27;95001&#x27;</span>,<span class="string">&#x27;Sname&#x27;</span>,<span class="string">&#x27;LiYing&#x27;</span></span><br><span class="line">put <span class="string">&#x27;student&#x27;</span>,<span class="string">&#x27;95001&#x27;</span>,<span class="string">&#x27;Ssex&#x27;</span>,<span class="string">&#x27;male&#x27;</span></span><br><span class="line">put <span class="string">&#x27;student&#x27;</span>,<span class="string">&#x27;95001&#x27;</span>,<span class="string">&#x27;Sage&#x27;</span>,<span class="string">&#x27;22&#x27;</span></span><br><span class="line">put <span class="string">&#x27;student&#x27;</span>,<span class="string">&#x27;95001&#x27;</span>,<span class="string">&#x27;Sdept&#x27;</span>,<span class="string">&#x27;CS&#x27;</span></span><br><span class="line">put <span class="string">&#x27;student&#x27;</span>,<span class="string">&#x27;95001&#x27;</span>,<span class="string">&#x27;course:math&#x27;</span>,<span class="string">&#x27;80&#x27;</span></span><br></pre></td></tr></table></figure>
<img src="/2022/11/12/Hadoop-%C2%A9-pepsi-wyl/1667009593262-a410dbca-ef7c-40a4-a27e-9b85634d0fad.png" class=""> 

<h3 id="查看数据"><a href="#查看数据" class="headerlink" title="查看数据"></a>查看数据</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 查看数据  查看表的某一个单元格数据</span></span><br><span class="line">get <span class="string">&#x27;student&#x27;</span>,<span class="string">&#x27;95001&#x27;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看数据  查看某个表的全部数据</span></span><br><span class="line">scan <span class="string">&#x27;student&#x27;</span></span><br></pre></td></tr></table></figure>
<img src="/2022/11/12/Hadoop-%C2%A9-pepsi-wyl/1667009618408-ea27b1ea-70f2-4d21-b877-e93b8931b4ad.png" class=""> 

<h3 id="删除数据"><a href="#删除数据" class="headerlink" title="删除数据"></a>删除数据</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 删除数据 删除一列数据</span></span><br><span class="line">delete <span class="string">&#x27;student&#x27;</span>,<span class="string">&#x27;95001&#x27;</span>,<span class="string">&#x27;Ssex&#x27;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 删除数据 删除一行数据</span></span><br><span class="line">deleteall <span class="string">&#x27;student&#x27;</span>,<span class="string">&#x27;95001&#x27;</span></span><br></pre></td></tr></table></figure>
<img src="/2022/11/12/Hadoop-%C2%A9-pepsi-wyl/1667009645508-cc7df4a1-61f1-4aaf-8c71-cfd99a8dff60.png" class=""> 

<h3 id="查询历史数据"><a href="#查询历史数据" class="headerlink" title="查询历史数据"></a>查询历史数据</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 创建teacher表，指定保存的版本数（假设指定为5）</span></span><br><span class="line">create <span class="string">&#x27;teacher&#x27;</span>,&#123;NAME=&gt;<span class="string">&#x27;username&#x27;</span>,VERSIONS=&gt;5&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment"># 插入数据，并更新数据，使其产生历史版本数据</span></span><br><span class="line">put <span class="string">&#x27;teacher&#x27;</span>,<span class="string">&#x27;91001&#x27;</span>,<span class="string">&#x27;username&#x27;</span>,<span class="string">&#x27;Mary&#x27;</span></span><br><span class="line">put <span class="string">&#x27;teacher&#x27;</span>,<span class="string">&#x27;91001&#x27;</span>,<span class="string">&#x27;username&#x27;</span>,<span class="string">&#x27;Mary1&#x27;</span></span><br><span class="line">put <span class="string">&#x27;teacher&#x27;</span>,<span class="string">&#x27;91001&#x27;</span>,<span class="string">&#x27;username&#x27;</span>,<span class="string">&#x27;Mary2&#x27;</span></span><br><span class="line">put <span class="string">&#x27;teacher&#x27;</span>,<span class="string">&#x27;91001&#x27;</span>,<span class="string">&#x27;username&#x27;</span>,<span class="string">&#x27;Mary3&#x27;</span></span><br><span class="line">put <span class="string">&#x27;teacher&#x27;</span>,<span class="string">&#x27;91001&#x27;</span>,<span class="string">&#x27;username&#x27;</span>,<span class="string">&#x27;Mary4&#x27;</span>  </span><br><span class="line">put <span class="string">&#x27;teacher&#x27;</span>,<span class="string">&#x27;91001&#x27;</span>,<span class="string">&#x27;username&#x27;</span>,<span class="string">&#x27;Mary5&#x27;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 查询指定查询的历史版本数</span></span><br><span class="line">get <span class="string">&#x27;teacher&#x27;</span>,<span class="string">&#x27;91001&#x27;</span>,&#123;COLUMN=&gt;<span class="string">&#x27;username&#x27;</span>,VERSIONS=&gt;5&#125;</span><br><span class="line">get <span class="string">&#x27;teacher&#x27;</span>,<span class="string">&#x27;91001&#x27;</span>,&#123;COLUMN=&gt;<span class="string">&#x27;username&#x27;</span>,VERSIONS=&gt;3&#125;</span><br></pre></td></tr></table></figure>
<img src="/2022/11/12/Hadoop-%C2%A9-pepsi-wyl/1667009898500-5a894fc3-1d57-4f06-ad35-9e38f220da42.png" class=""> 

<h3 id="退出"><a href="#退出" class="headerlink" title="退出"></a>退出</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">exit</span></span><br></pre></td></tr></table></figure>
<img src="/2022/11/12/Hadoop-%C2%A9-pepsi-wyl/1667009912071-112ede8e-1567-4d87-8998-55f7510cfc41.png" class=""> 

<h2 id="Idae编程"><a href="#Idae编程" class="headerlink" title="Idae编程"></a>Idae编程</h2><p>代码连接 <a target="_blank" rel="noopener" href="https://github.com/pepsi-wyl/Hbase_API">https://github.com/pepsi-wyl/Hbase_API</a></p>
<h3 id="Windows添加映射"><a href="#Windows添加映射" class="headerlink" title="Windows添加映射"></a>Windows添加映射</h3><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"># C:\Windows\System32\drivers\etc\hosts</span><br><span class="line"></span><br><span class="line"># 添加映射</span><br><span class="line"><span class="number">192.168</span><span class="number">.131</span><span class="number">.144</span> hadoop</span><br></pre></td></tr></table></figure>

<h3 id="创建Maven并且添加依赖"><a href="#创建Maven并且添加依赖" class="headerlink" title="创建Maven并且添加依赖"></a>创建Maven并且添加依赖</h3><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">dependencies</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.hbase<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>hbase-server<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">version</span>&gt;</span>2.2.2<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.hbase<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>hbase-client<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">version</span>&gt;</span>2.2.2<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependencies</span>&gt;</span></span><br></pre></td></tr></table></figure>

<p>依赖版本要与HBase版本对应</p>
<img src="/2022/11/12/Hadoop-%C2%A9-pepsi-wyl/1667028051579-0cd82888-c116-4d67-9c61-b2bf7349fdc1.png" class=""> 


<h3 id="编写代码"><a href="#编写代码" class="headerlink" title="编写代码"></a>编写代码</h3><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> utils;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.conf.Configuration;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.hbase.*;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.hbase.client.*;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.hbase.util.Bytes;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.io.IOException;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@author</span> by pepsi-wyl</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@date</span> 2022-10-29 11:19</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">ExampleForHBase</span> &#123;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> Configuration configuration;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> Connection connection;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> Admin admin;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> IOException &#123;</span><br><span class="line">        init();</span><br><span class="line">        createTable(<span class="string">&quot;student&quot;</span>, <span class="keyword">new</span> <span class="title class_">String</span>[]&#123;<span class="string">&quot;score&quot;</span>&#125;);</span><br><span class="line">        insertData(<span class="string">&quot;student&quot;</span>, <span class="string">&quot;zhangsan&quot;</span>, <span class="string">&quot;score&quot;</span>, <span class="string">&quot;English&quot;</span>, <span class="string">&quot;69&quot;</span>);</span><br><span class="line">        insertData(<span class="string">&quot;student&quot;</span>, <span class="string">&quot;zhangsan&quot;</span>, <span class="string">&quot;score&quot;</span>, <span class="string">&quot;Math&quot;</span>, <span class="string">&quot;86&quot;</span>);</span><br><span class="line">        insertData(<span class="string">&quot;student&quot;</span>, <span class="string">&quot;zhangsan&quot;</span>, <span class="string">&quot;score&quot;</span>, <span class="string">&quot;Computer&quot;</span>, <span class="string">&quot;77&quot;</span>);</span><br><span class="line">        getData(<span class="string">&quot;student&quot;</span>, <span class="string">&quot;zhangsan&quot;</span>, <span class="string">&quot;score&quot;</span>, <span class="string">&quot;English&quot;</span>);</span><br><span class="line">        close();</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">init</span><span class="params">()</span> &#123;</span><br><span class="line">        configuration = HBaseConfiguration.create();</span><br><span class="line">        configuration.set(<span class="string">&quot;hbase.rootdir&quot;</span>, <span class="string">&quot;hdfs://192.168.131.144:9000/hbase&quot;</span>);</span><br><span class="line">        configuration.set(<span class="string">&quot;hbase.zookeeper.quorum&quot;</span>, <span class="string">&quot;192.168.131.144&quot;</span>);</span><br><span class="line">        configuration.set(<span class="string">&quot;hbase.zookeeper.property.clientPort&quot;</span>, <span class="string">&quot;2181&quot;</span>);</span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">            connection = ConnectionFactory.createConnection(configuration);</span><br><span class="line">            admin = connection.getAdmin();</span><br><span class="line">        &#125; <span class="keyword">catch</span> (IOException e) &#123;</span><br><span class="line">            e.printStackTrace();</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">close</span><span class="params">()</span> &#123;</span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">            <span class="keyword">if</span> (admin != <span class="literal">null</span>) &#123;</span><br><span class="line">                admin.close();</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="keyword">if</span> (<span class="literal">null</span> != connection) &#123;</span><br><span class="line">                connection.close();</span><br><span class="line">            &#125;</span><br><span class="line">        &#125; <span class="keyword">catch</span> (IOException e) &#123;</span><br><span class="line">            e.printStackTrace();</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">createTable</span><span class="params">(String myTableName, String[] colFamily)</span> <span class="keyword">throws</span> IOException &#123;</span><br><span class="line">        <span class="type">TableName</span> <span class="variable">tableName</span> <span class="operator">=</span> TableName.valueOf(myTableName);</span><br><span class="line">        <span class="keyword">if</span> (admin.tableExists(tableName)) &#123;</span><br><span class="line">            System.out.println(<span class="string">&quot;talbe is exists!&quot;</span>);</span><br><span class="line">        &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">            <span class="type">TableDescriptorBuilder</span> <span class="variable">tableDescriptor</span> <span class="operator">=</span> TableDescriptorBuilder.newBuilder(tableName);</span><br><span class="line">            <span class="keyword">for</span> (String str : colFamily) &#123;</span><br><span class="line">                <span class="type">ColumnFamilyDescriptor</span> <span class="variable">family</span> <span class="operator">=</span> ColumnFamilyDescriptorBuilder.newBuilder(Bytes.toBytes(str)).build();</span><br><span class="line">                tableDescriptor.setColumnFamily(family);</span><br><span class="line">            &#125;</span><br><span class="line">            admin.createTable(tableDescriptor.build());</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">insertData</span><span class="params">(String tableName, String rowKey, String colFamily, String col, String val)</span> <span class="keyword">throws</span> IOException &#123;</span><br><span class="line">        <span class="type">Table</span> <span class="variable">table</span> <span class="operator">=</span> connection.getTable(TableName.valueOf(tableName));</span><br><span class="line">        <span class="type">Put</span> <span class="variable">put</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Put</span>(rowKey.getBytes());</span><br><span class="line">        put.addColumn(colFamily.getBytes(), col.getBytes(), val.getBytes());</span><br><span class="line">        table.put(put);</span><br><span class="line">        table.close();</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">getData</span><span class="params">(String tableName, String rowKey, String colFamily, String col)</span> <span class="keyword">throws</span> IOException &#123;</span><br><span class="line">        <span class="type">Table</span> <span class="variable">table</span> <span class="operator">=</span> connection.getTable(TableName.valueOf(tableName));</span><br><span class="line">        <span class="type">Get</span> <span class="variable">get</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Get</span>(rowKey.getBytes());</span><br><span class="line">        get.addColumn(colFamily.getBytes(), col.getBytes());</span><br><span class="line">        <span class="type">Result</span> <span class="variable">result</span> <span class="operator">=</span> table.get(get);</span><br><span class="line">        System.out.println(<span class="keyword">new</span> <span class="title class_">String</span>(result.getValue(colFamily.getBytes(), col == <span class="literal">null</span> ? <span class="literal">null</span> : col.getBytes())));</span><br><span class="line">        table.close();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<img src="/2022/11/12/Hadoop-%C2%A9-pepsi-wyl/1667028401831-86be6eae-9f74-433a-b192-5c196b7e6978.png" class=""> 

<h1 id="Zookeeper技术"><a href="#Zookeeper技术" class="headerlink" title="Zookeeper技术"></a>Zookeeper技术</h1><h2 id="安装-1"><a href="#安装-1" class="headerlink" title="安装"></a>安装</h2><h3 id="单机安装-1"><a href="#单机安装-1" class="headerlink" title="单机安装"></a>单机安装</h3><p>这种配置方式下没有Zookeeper副本，所以如果Zookeeper服务器出现故障，Zookeeper服务将会停止。这种应用模式主要用在测试或demo的情况下，在生产环境下一般不会采用。</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 切换路径</span></span><br><span class="line"><span class="built_in">cd</span> /home/hadoop</span><br><span class="line"></span><br><span class="line"><span class="comment"># 解决颁发的证书已经过期问题</span></span><br><span class="line">yum install -y ca-certificates</span><br><span class="line"></span><br><span class="line"><span class="comment"># 获取安装包</span></span><br><span class="line">wget https://dlcdn.apache.org/zookeeper/zookeeper-3.6.3/apache-zookeeper-3.6.3-bin.tar.gz</span><br><span class="line"></span><br><span class="line"><span class="comment"># 解压安装包</span></span><br><span class="line">tar -zxvf apache-zookeeper-3.6.3-bin.tar.gz</span><br><span class="line"></span><br><span class="line"><span class="comment"># 重命名</span></span><br><span class="line"><span class="built_in">mv</span> apache-zookeeper-3.6.3-bin zookeeper</span><br><span class="line"></span><br><span class="line"><span class="comment"># 赋予权限</span></span><br><span class="line">sudo <span class="built_in">chown</span> hadoop:hadoop -R /home/hadoop/zookeeper</span><br><span class="line"></span><br><span class="line"><span class="comment"># 删除安装包</span></span><br><span class="line"><span class="built_in">rm</span> -rf apache-zookeeper-3.6.3-bin.tar.gz</span><br></pre></td></tr></table></figure>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 创建路径</span></span><br><span class="line"><span class="built_in">mkdir</span> /home/hadoop/zookeeper/one</span><br><span class="line"></span><br><span class="line"><span class="comment"># 创建数据目录</span></span><br><span class="line"><span class="built_in">mkdir</span> /home/hadoop/zookeeper/one/data</span><br><span class="line"></span><br><span class="line"><span class="comment"># 复制配置文件</span></span><br><span class="line"><span class="built_in">cp</span> /home/hadoop/zookeeper/conf/zoo_sample.cfg /home/hadoop/zookeeper/conf/zoo.cfg</span><br></pre></td></tr></table></figure>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 修改配置文件</span></span><br><span class="line">vim /home/hadoop/zookeeper/conf/zoo.cfg</span><br><span class="line"></span><br><span class="line">ickTime=2000</span><br><span class="line">dataDir=/home/hadoop/zookeeper/one/data</span><br><span class="line">clientPort=2181</span><br></pre></td></tr></table></figure>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 启动zookeeper服务</span></span><br><span class="line">/home/hadoop/zookeeper/bin/zkServer.sh start</span><br><span class="line"></span><br><span class="line"><span class="comment"># 关闭zookeeper服务</span></span><br><span class="line">/home/hadoop/zookeeper/bin/zkServer.sh stop</span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看zookeeper服务的运行状态</span></span><br><span class="line">/home/hadoop/zookeeper/bin/zkServer.sh status</span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看系统进程，看到“QuorumPeerMain”进程，表示Zookeeper已经启动</span></span><br><span class="line">jps</span><br></pre></td></tr></table></figure>
<img src="/2022/11/12/Hadoop-%C2%A9-pepsi-wyl/1667890477529-cc2150a8-d739-47f0-9fa8-738ae47fa62b.png" class=""> 

<h3 id="伪分布式安装"><a href="#伪分布式安装" class="headerlink" title="伪分布式安装"></a>伪分布式安装</h3><p>伪集群模式就是在单机模拟集群的Zookeeper服务。在Zookeeper的参数配置中，clientPort参数用来配置客户端连接Zookeeper的端口。伪分布式是使用每个配置文档模拟一台机器，也就是说，需要在单台机器上运行多个Zookeeper实例。但是必须要保证各个配置文档的clientPort不冲突即可。</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 创建集群目录</span></span><br><span class="line"><span class="built_in">mkdir</span> /home/hadoop/zookeeper/master</span><br><span class="line"></span><br><span class="line"><span class="built_in">mkdir</span> /home/hadoop/zookeeper/master/conf</span><br><span class="line"><span class="built_in">mkdir</span> /home/hadoop/zookeeper/master/data</span><br><span class="line"><span class="built_in">mkdir</span> /home/hadoop/zookeeper/master/data/one</span><br><span class="line"><span class="built_in">mkdir</span> /home/hadoop/zookeeper/master/data/two</span><br><span class="line"><span class="built_in">mkdir</span> /home/hadoop/zookeeper/master/data/three</span><br><span class="line"><span class="built_in">mkdir</span> /home/hadoop/zookeeper/master/datalog</span><br><span class="line"><span class="built_in">mkdir</span> /home/hadoop/zookeeper/master/datalog/one</span><br><span class="line"><span class="built_in">mkdir</span> /home/hadoop/zookeeper/master/datalog/two</span><br><span class="line"><span class="built_in">mkdir</span> /home/hadoop/zookeeper/master/datalog/three</span><br><span class="line"></span><br><span class="line"><span class="comment"># 复制配置文件</span></span><br><span class="line"><span class="built_in">cp</span> /home/hadoop/zookeeper/conf/zoo_sample.cfg /home/hadoop/zookeeper/master/conf/zoo1.cfg</span><br><span class="line"><span class="built_in">cp</span> /home/hadoop/zookeeper/conf/zoo_sample.cfg /home/hadoop/zookeeper/master/conf/zoo2.cfg</span><br><span class="line"><span class="built_in">cp</span> /home/hadoop/zookeeper/conf/zoo_sample.cfg /home/hadoop/zookeeper/master/conf/zoo3.cfg</span><br></pre></td></tr></table></figure>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line">vim /home/hadoop/zookeeper/master/conf/zoo1.cfg</span><br><span class="line">tickTime=2000</span><br><span class="line">initLimit=10</span><br><span class="line">syncLimit=5</span><br><span class="line">dataDir=/home/hadoop/zookeeper/master/data/one</span><br><span class="line">dataLogDir=/home/hadoop/zookeeper/master/datalog/one</span><br><span class="line">clientPort=2181</span><br><span class="line">server.1=127.0.0.1:2888:3888</span><br><span class="line">server.2=127.0.0.1:2889:3889</span><br><span class="line">server.3=127.0.0.1:2890:3890</span><br><span class="line">maxClientCnxns=60</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">vim /home/hadoop/zookeeper/master/conf/zoo2.cfg</span><br><span class="line">tickTime=2000</span><br><span class="line">initLimit=10</span><br><span class="line">syncLimit=5</span><br><span class="line">dataDir=/home/hadoop/zookeeper/master/data/two</span><br><span class="line">dataLogDir=/home/hadoop/zookeeper/master/datalog/two</span><br><span class="line">clientPort=2182</span><br><span class="line">server.1=127.0.0.1:2888:3888</span><br><span class="line">server.2=127.0.0.1:2889:3889</span><br><span class="line">server.3=127.0.0.1:2890:3890</span><br><span class="line">maxClientCnxns=60</span><br><span class="line"></span><br><span class="line">vim /home/hadoop/zookeeper/master/conf/zoo3.cfg</span><br><span class="line">tickTime=2000</span><br><span class="line">initLimit=10</span><br><span class="line">syncLimit=5</span><br><span class="line">dataDir=/home/hadoop/zookeeper/master/data/three</span><br><span class="line">dataLogDir=/home/hadoop/zookeeper/master/datalog/three</span><br><span class="line">clientPort=2183</span><br><span class="line">server.1=127.0.0.1:2888:3888</span><br><span class="line">server.2=127.0.0.1:2889:3889</span><br><span class="line">server.3=127.0.0.1:2890:3890</span><br><span class="line">maxClientCnxns=60</span><br></pre></td></tr></table></figure>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># myid文件缺失 https://blog.csdn.net/a_bang/article/details/72825929</span></span><br><span class="line"></span><br><span class="line">vim /home/hadoop/zookeeper/master/data/one/myid</span><br><span class="line">1</span><br><span class="line">vim /home/hadoop/zookeeper/master/data/two/myid</span><br><span class="line">2</span><br><span class="line">vim /home/hadoop/zookeeper/master/data/three/myid</span><br><span class="line">3</span><br></pre></td></tr></table></figure>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 启动</span></span><br><span class="line">/home/hadoop/zookeeper/bin/zkServer.sh start /home/hadoop/zookeeper/master/conf/zoo1.cfg</span><br><span class="line">/home/hadoop/zookeeper/bin/zkServer.sh start /home/hadoop/zookeeper/master/conf/zoo2.cfg</span><br><span class="line">/home/hadoop/zookeeper/bin/zkServer.sh start /home/hadoop/zookeeper/master/conf/zoo3.cfg</span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看状态</span></span><br><span class="line">/home/hadoop/zookeeper/bin/zkServer.sh status /home/hadoop/zookeeper/master/conf/zoo1.cfg</span><br><span class="line">/home/hadoop/zookeeper/bin/zkServer.sh status /home/hadoop/zookeeper/master/conf/zoo2.cfg</span><br><span class="line">/home/hadoop/zookeeper/bin/zkServer.sh status /home/hadoop/zookeeper/master/conf/zoo3.cfg</span><br><span class="line"></span><br><span class="line"><span class="comment"># 关闭</span></span><br><span class="line">/home/hadoop/zookeeper/bin/zkServer.sh stop /home/hadoop/zookeeper/master/conf/zoo1.cfg</span><br><span class="line">/home/hadoop/zookeeper/bin/zkServer.sh stop /home/hadoop/zookeeper/master/conf/zoo2.cfg</span><br><span class="line">/home/hadoop/zookeeper/bin/zkServer.sh stop /home/hadoop/zookeeper/master/conf/zoo3.cfg</span><br></pre></td></tr></table></figure>
<img src="/2022/11/12/Hadoop-%C2%A9-pepsi-wyl/1667895541526-b296cb63-4d17-446c-ab82-9cd8e061d85b.png" class=""> 
<img src="/2022/11/12/Hadoop-%C2%A9-pepsi-wyl/1667895570296-717dc9d3-af3a-4e6f-919a-4f031694f61c.png" class=""> 
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">/home/hadoop/zookeeper/bin/zkServer.sh start-foreground /home/hadoop/zookeeper/master/conf/zoo1.cfg</span><br></pre></td></tr></table></figure>

<h3 id="分布式安装-选作-1"><a href="#分布式安装-选作-1" class="headerlink" title="分布式安装(选作)"></a>分布式安装(选作)</h3><p>在这种模式下可以获得可靠的Zookeeper服务，只要集群中的大多数Zookeeper服务启动了，那么总的Zookeeper服务将是可用的。分布式模式下的配置与伪分布式最大的不同是Zookeeper实例分布在多台机器上。</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 切换路径</span></span><br><span class="line"><span class="built_in">cd</span> /opt</span><br><span class="line"></span><br><span class="line"><span class="comment"># 解决颁发的证书已经过期问题</span></span><br><span class="line">yum install -y ca-certificates</span><br><span class="line"></span><br><span class="line"><span class="comment"># 获取安装包</span></span><br><span class="line">wget https://dlcdn.apache.org/zookeeper/zookeeper-3.6.3/apache-zookeeper-3.6.3-bin.tar.gz</span><br><span class="line"></span><br><span class="line"><span class="comment"># 解压安装包</span></span><br><span class="line">tar -zxvf apache-zookeeper-3.6.3-bin.tar.gz</span><br><span class="line"></span><br><span class="line"><span class="comment"># 重命名</span></span><br><span class="line"><span class="built_in">mv</span> apache-zookeeper-3.6.3-bin zookeeper</span><br><span class="line"></span><br><span class="line"><span class="comment"># 删除安装包</span></span><br><span class="line"><span class="built_in">rm</span> -rf apache-zookeeper-3.6.3-bin.tar.gz</span><br><span class="line"></span><br><span class="line"><span class="comment"># 创建数据目录</span></span><br><span class="line"><span class="built_in">mkdir</span> /opt/zookeeper/data</span><br><span class="line"></span><br><span class="line"><span class="comment"># 创建数据目录日志目录</span></span><br><span class="line"><span class="built_in">mkdir</span> /opt/zookeeper/datalog</span><br><span class="line"></span><br><span class="line"><span class="comment"># 复制配置文件</span></span><br><span class="line"><span class="built_in">cp</span> /opt/zookeeper/conf/zoo_sample.cfg /opt/zookeeper/conf/zoo.cfg</span><br><span class="line"></span><br><span class="line"><span class="comment"># 编写配置文件</span></span><br><span class="line">vim /opt/zookeeper/conf/zoo.cfg</span><br><span class="line"></span><br><span class="line">tickTime=2000</span><br><span class="line">initLimit=10</span><br><span class="line">syncLimit=5</span><br><span class="line">dataDir=/opt/zookeeper/data</span><br><span class="line">dataLogDir=/opt/zookeeper/datalog</span><br><span class="line">clientPort=2182</span><br><span class="line">server.1=192.168.131.145:2887:3887</span><br><span class="line">server.2=192.168.131.146:2888:3888</span><br><span class="line">server.3=192.168.131.147:2899:3899</span><br><span class="line"></span><br><span class="line"><span class="comment"># hadoop1中</span></span><br><span class="line">vim /opt/zookeeper/data/myid</span><br><span class="line">1</span><br><span class="line"></span><br><span class="line"><span class="comment"># hadoop2中</span></span><br><span class="line">vim /opt/zookeeper/data/myid</span><br><span class="line">2</span><br><span class="line"></span><br><span class="line"><span class="comment"># hadoop3中</span></span><br><span class="line">vim /opt/zookeeper/data/myid</span><br><span class="line">3</span><br><span class="line"></span><br><span class="line"><span class="comment"># 启动zookeeper服务</span></span><br><span class="line">/opt/zookeeper/bin/zkServer.sh start</span><br><span class="line"></span><br><span class="line"><span class="comment"># 关闭zookeeper服务</span></span><br><span class="line">/opt/zookeeper/bin/zkServer.sh stop</span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看zookeeper服务的运行状态</span></span><br><span class="line">/opt/zookeeper/bin/zkServer.sh status</span><br></pre></td></tr></table></figure>
<img src="/2022/11/12/Hadoop-%C2%A9-pepsi-wyl/1667898771414-cb30096f-32f8-4352-8019-fca123110223.png" class=""> 
<img src="/2022/11/12/Hadoop-%C2%A9-pepsi-wyl/1667898784655-8706b29b-c514-460c-9dfb-416a0285109d.png" class=""> 
<img src="/2022/11/12/Hadoop-%C2%A9-pepsi-wyl/1667898803162-34d2506c-ce20-4aa6-8dbe-42cad1b29bab.png" class=""> 

<h2 id="操作"><a href="#操作" class="headerlink" title="操作"></a>操作</h2><h3 id="0-启动Cli"><a href="#0-启动Cli" class="headerlink" title="0.启动Cli"></a>0.启动Cli</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 启动Cli</span></span><br><span class="line">/home/hadoop/zookeeper/bin/zkCli.sh</span><br></pre></td></tr></table></figure>
<img src="/2022/11/12/Hadoop-%C2%A9-pepsi-wyl/1667896052438-415c3bc8-93d5-4738-8669-a15c6b737d52.png" class=""> 

<h3 id="1-创建Znodes"><a href="#1-创建Znodes" class="headerlink" title="1.创建Znodes"></a>1.创建Znodes</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 创建节点</span></span><br><span class="line">create /path /data</span><br><span class="line">create /FirstZnode <span class="string">&quot;Myfirstzookeeper-pp&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 创建顺序节点 flag：-s</span></span><br><span class="line">create -s /path /data</span><br><span class="line">create -s /FirstZnode <span class="string">&quot;second-data&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 创建临时节点 flag：-e</span></span><br><span class="line">create -e /path /data</span><br><span class="line">create -e /SecondZnode <span class="string">&quot;Ephemeral-data&quot;</span></span><br></pre></td></tr></table></figure>
<img src="/2022/11/12/Hadoop-%C2%A9-pepsi-wyl/1667896521579-d76bca1b-e077-42f3-a65f-97e199519e06.png" class=""> 

<h3 id="2-获取数据"><a href="#2-获取数据" class="headerlink" title="2.获取数据"></a>2.获取数据</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 获取数据</span></span><br><span class="line">get /path</span><br><span class="line"></span><br><span class="line">get /FirstZnode</span><br><span class="line">get /FirstZnode0000000001</span><br></pre></td></tr></table></figure>
<img src="/2022/11/12/Hadoop-%C2%A9-pepsi-wyl/1667896881402-e91bfbc6-a817-4b95-b3ea-131552d199a9.png" class=""> 
<img src="/2022/11/12/Hadoop-%C2%A9-pepsi-wyl/1667897285456-0012e270-7b8d-4a1c-a860-69c948eb9f11.png" class=""> 

<h3 id="3-Watch（监视）"><a href="#3-Watch（监视）" class="headerlink" title="3.Watch（监视）"></a>3.Watch（监视）</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Watch（监视）</span></span><br><span class="line">get /path [watch] 1</span><br><span class="line"></span><br><span class="line">get /FirstZnode 1</span><br></pre></td></tr></table></figure>
<img src="/2022/11/12/Hadoop-%C2%A9-pepsi-wyl/1667896791268-e2183bd6-67e8-4212-921f-60ec13c90008.png" class=""> 

<h3 id="4-设置数据"><a href="#4-设置数据" class="headerlink" title="4.设置数据"></a>4.设置数据</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 设置/更改数据</span></span><br><span class="line"><span class="built_in">set</span> /path /data</span><br><span class="line"></span><br><span class="line"><span class="built_in">set</span> /SecondZnode Data-updated</span><br><span class="line"><span class="built_in">set</span> /SecondZnode abc</span><br></pre></td></tr></table></figure>
<img src="/2022/11/12/Hadoop-%C2%A9-pepsi-wyl/1667896957320-a7c16bc8-fc41-401c-808c-7bc092173e63.png" class=""> 

<h3 id="5-创建znode子节点"><a href="#5-创建znode子节点" class="headerlink" title="5.创建znode子节点"></a>5.创建znode子节点</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 创建znode子节点</span></span><br><span class="line">create /parent/path/subnode/path /data</span><br><span class="line"></span><br><span class="line">create /FirstZnode/Child1 firstchildren</span><br></pre></td></tr></table></figure>
<img src="/2022/11/12/Hadoop-%C2%A9-pepsi-wyl/1667897100634-28744b14-5faf-4ac7-8981-d1353c1a30d5.png" class=""> 

<h3 id="6-列出znode的子节点"><a href="#6-列出znode的子节点" class="headerlink" title="6.列出znode的子节点"></a>6.列出znode的子节点</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 列出znode的子节点</span></span><br><span class="line"><span class="built_in">ls</span> /path</span><br><span class="line"></span><br><span class="line"><span class="built_in">ls</span> /FirstZnode</span><br></pre></td></tr></table></figure>
<img src="/2022/11/12/Hadoop-%C2%A9-pepsi-wyl/1667897128446-054aab38-e54c-48b1-84bc-f4319f5bad49.png" class=""> 

<h3 id="7-检查状态"><a href="#7-检查状态" class="headerlink" title="7.检查状态"></a>7.检查状态</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 检查状态</span></span><br><span class="line"><span class="built_in">stat</span> /path</span><br><span class="line"></span><br><span class="line"><span class="built_in">stat</span> /FirstZnode</span><br></pre></td></tr></table></figure>
<img src="/2022/11/12/Hadoop-%C2%A9-pepsi-wyl/1667897141714-96981414-bf40-434c-bfc8-1bb9c069fa95.png" class=""> 

<h3 id="8-删除Znode"><a href="#8-删除Znode" class="headerlink" title="8. 删除Znode"></a>8. 删除Znode</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 删除Znode</span></span><br><span class="line">delete /path</span><br><span class="line"></span><br><span class="line">delete /SecondZnode</span><br></pre></td></tr></table></figure>
<img src="/2022/11/12/Hadoop-%C2%A9-pepsi-wyl/1667897363718-2534fed6-adbe-4dcd-8acb-1ac6148d0baa.png" class=""> 

<h1 id="数据仓库Hive"><a href="#数据仓库Hive" class="headerlink" title="数据仓库Hive"></a>数据仓库Hive</h1><h2 id="安装-2"><a href="#安装-2" class="headerlink" title="安装"></a>安装</h2><h3 id="安装Mysql"><a href="#安装Mysql" class="headerlink" title="安装Mysql"></a>安装Mysql</h3><p>本次使用Docker安装Mysql  docker详解为<a target="_blank" rel="noopener" href="https://www.yuque.com/pepsiwyl/blog/ghlc1t">https://www.yuque.com/pepsiwyl/blog/ghlc1t</a><br>直接安装可以参考 <a target="_blank" rel="noopener" href="https://www.yuque.com/pepsiwyl/blog/zalhzm">https://www.yuque.com/pepsiwyl/blog/zalhzm</a></p>
<h4 id="安装Docker"><a href="#安装Docker" class="headerlink" title="安装Docker"></a>安装Docker</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 安装命令</span></span><br><span class="line">curl -fsSL https://get.docker.com | bash -s docker --mirror Aliyun</span><br><span class="line"></span><br><span class="line"><span class="comment"># 将当前用户加入Docker组</span></span><br><span class="line">sudo groupadd docker            <span class="comment"># 创建Docker组</span></span><br><span class="line">sudo usermod -aG docker <span class="variable">$USER</span>   <span class="comment"># 将当前用户加入Docker组</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 启动docker</span></span><br><span class="line">systemctl start docker    <span class="comment"># 开启服务</span></span><br><span class="line">systemctl <span class="built_in">enable</span> docker   <span class="comment"># 开机自启服务</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 验证doker版本</span></span><br><span class="line">docker version</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 配置阿里云加速镜像 执行以下脚本即可</span></span><br><span class="line">sudo <span class="built_in">mkdir</span> -p /etc/docker</span><br><span class="line">sudo <span class="built_in">tee</span> /etc/docker/daemon.json &lt;&lt;-<span class="string">&#x27;EOF&#x27;</span></span><br><span class="line">&#123;</span><br><span class="line">  <span class="string">&quot;registry-mirrors&quot;</span>: [<span class="string">&quot;https://fimlvmx5.mirror.aliyuncs.com&quot;</span>]</span><br><span class="line">&#125;</span><br><span class="line">EOF</span><br><span class="line">sudo systemctl daemon-reload</span><br><span class="line">sudo systemctl restart docker</span><br></pre></td></tr></table></figure>
<img src="/2022/11/12/Hadoop-%C2%A9-pepsi-wyl/1667906764198-b2da97bf-6e62-4abc-afa7-e07416670a76.png" class=""> 

<h4 id="启动Mysql容器"><a href="#启动Mysql容器" class="headerlink" title="启动Mysql容器"></a>启动Mysql容器</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 安装mysql  账号root 密码root</span></span><br><span class="line">docker run -p 3306:3306 -e MYSQL_ROOT_PASSWORD=root -v mysql:/var/lib/mysql -d --restart=always --name mysql8.0 mysql:8.0.24</span><br></pre></td></tr></table></figure>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 查看mysql是否启动成功</span></span><br><span class="line">docker ps</span><br></pre></td></tr></table></figure>
<img src="/2022/11/12/Hadoop-%C2%A9-pepsi-wyl/1667906236888-d77b6f9b-287f-4db4-9501-dab2430ede21.png" class=""> 

<h4 id="创建hive库"><a href="#创建hive库" class="headerlink" title="创建hive库"></a>创建hive库</h4><img src="/2022/11/12/Hadoop-%C2%A9-pepsi-wyl/1667908007042-ef0a9be7-ba52-490b-a51d-9303fdd423d4.png" class=""> 

<h3 id="安装Hive"><a href="#安装Hive" class="headerlink" title="安装Hive"></a>安装Hive</h3><h4 id="安装-3"><a href="#安装-3" class="headerlink" title="安装"></a>安装</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 切换路径</span></span><br><span class="line"><span class="built_in">cd</span> /opt</span><br><span class="line"></span><br><span class="line"><span class="comment"># 下载安装包  网址: https://dlcdn.apache.org/hive/</span></span><br><span class="line">wget https://dlcdn.apache.org/hive/hive-3.1.2/apache-hive-3.1.2-bin.tar.gz</span><br><span class="line"></span><br><span class="line"><span class="comment"># 解压</span></span><br><span class="line">tar -zxvf apache-hive-3.1.2-bin.tar.gz</span><br><span class="line"></span><br><span class="line"><span class="comment"># 重命名</span></span><br><span class="line"><span class="built_in">mv</span> apache-hive-3.1.2-bin hive</span><br><span class="line"></span><br><span class="line"><span class="comment"># 删除安装包</span></span><br><span class="line"><span class="built_in">rm</span> -rf apache-hive-3.1.2-bin.tar.gz</span><br><span class="line"></span><br><span class="line"><span class="comment"># 添加环境变量</span></span><br><span class="line">vim /etc/profile</span><br><span class="line">	<span class="comment">#hive安装目录</span></span><br><span class="line">	<span class="built_in">export</span> HIVE_HOME=/opt/hive  </span><br><span class="line">	<span class="built_in">export</span> PATH=<span class="variable">$PATH</span>:<span class="variable">$HIVE_HOME</span>/bin</span><br><span class="line"><span class="comment"># 更新环境变量</span></span><br><span class="line"><span class="built_in">source</span> /etc/profile</span><br><span class="line"></span><br><span class="line"><span class="comment"># 检测Hive是否安装成功</span></span><br><span class="line">hive --version</span><br></pre></td></tr></table></figure>
<img src="/2022/11/12/Hadoop-%C2%A9-pepsi-wyl/1667906665017-ab18ac10-38c0-45a0-a09e-baa8268b5031.png" class=""> 

<h4 id="添加jar包"><a href="#添加jar包" class="headerlink" title="添加jar包"></a>添加jar包</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 切换路径</span></span><br><span class="line"><span class="built_in">cd</span> /opt</span><br><span class="line"></span><br><span class="line"><span class="comment"># 下载rpm包</span></span><br><span class="line">wget https://downloads.mysql.com/archives/get/p/3/file/mysql-connector-java-8.0.24-1.el7.noarch.rpm</span><br><span class="line"></span><br><span class="line"><span class="comment"># 解压rpm包</span></span><br><span class="line">rpm2cpio mysql-connector-java-8.0.24-1.el7.noarch.rpm | cpio -div</span><br><span class="line"></span><br><span class="line"><span class="comment"># 删除rpm包</span></span><br><span class="line"><span class="built_in">rm</span> -rf mysql-connector-java-8.0.24-1.el7.noarch.rpm</span><br><span class="line"></span><br><span class="line"><span class="comment"># 添加jar包</span></span><br><span class="line"><span class="built_in">cp</span> /opt/usr/share/java/mysql-connector-java.jar /opt/hive/lib</span><br><span class="line"></span><br><span class="line"><span class="comment"># 删除解压文件</span></span><br><span class="line"><span class="built_in">rm</span> -rf /opt/usr</span><br></pre></td></tr></table></figure>

<h4 id="配置Hive"><a href="#配置Hive" class="headerlink" title="配置Hive"></a>配置Hive</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 切换路径</span></span><br><span class="line"><span class="built_in">cd</span> /opt/hive/conf</span><br><span class="line"></span><br><span class="line"><span class="comment"># 将hive-default.xml.template文件重命名为hive-default.xml</span></span><br><span class="line"><span class="built_in">mv</span> hive-default.xml.template hive-default.xml</span><br><span class="line"></span><br><span class="line"><span class="comment"># 新建一个文件hive-site.xml</span></span><br><span class="line">vim hive-site.xml</span><br></pre></td></tr></table></figure>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&lt;?xml version=<span class="string">&quot;1.0&quot;</span> encoding=<span class="string">&quot;UTF-8&quot;</span> standalone=<span class="string">&quot;no&quot;</span>?&gt;</span></span><br><span class="line"><span class="meta">&lt;?xml-stylesheet type=<span class="string">&quot;text/xsl&quot;</span> href=<span class="string">&quot;configuration.xsl&quot;</span>?&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>javax.jdo.option.ConnectionURL<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="comment">&lt;!--Mysql服务器IP地址--&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>jdbc:mysql://192.168.131.144:3306/hive?useUnicode=true<span class="symbol">&amp;amp;</span>serverTimezone=UTC<span class="symbol">&amp;amp;</span>useUnicode=true<span class="symbol">&amp;amp;</span>characterEncoding=utf8<span class="symbol">&amp;amp;</span>useSSL=false<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">description</span>&gt;</span>JDBC connect string for a JDBC metastore<span class="tag">&lt;/<span class="name">description</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>javax.jdo.option.ConnectionDriverName<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>com.mysql.cj.jdbc.Driver<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">description</span>&gt;</span>Driver class name for a JDBC metastore<span class="tag">&lt;/<span class="name">description</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>javax.jdo.option.ConnectionUserName<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>root<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">description</span>&gt;</span>username to use against metastore database<span class="tag">&lt;/<span class="name">description</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>javax.jdo.option.ConnectionPassword<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>root<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">description</span>&gt;</span>password to use against metastore database<span class="tag">&lt;/<span class="name">description</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br></pre></td></tr></table></figure>

<h4 id="执行初始化命令"><a href="#执行初始化命令" class="headerlink" title="执行初始化命令"></a>执行初始化命令</h4><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">schematool -dbType mysql -initSchema</span><br></pre></td></tr></table></figure>
<img src="/2022/11/12/Hadoop-%C2%A9-pepsi-wyl/1667909425435-7baa3dde-2cfb-4193-b212-d52882331ddd.png" class=""> 
<img src="/2022/11/12/Hadoop-%C2%A9-pepsi-wyl/1667909445175-45d0536f-1413-469c-9987-f445c81eab98.png" class=""> 

<h5 id="BUG"><a href="#BUG" class="headerlink" title="BUG"></a>BUG</h5><img src="/2022/11/12/Hadoop-%C2%A9-pepsi-wyl/1667909533430-b9924b3b-75ed-4520-a08b-637c65ba7ffc.png" class=""> 

<p>解决方法   <a target="_blank" rel="noopener" href="https://www.cnblogs.com/syq816/p/12632028.html">https://www.cnblogs.com/syq816/p/12632028.html</a></p>
<h4 id="启动-1"><a href="#启动-1" class="headerlink" title="启动"></a>启动</h4><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"># 启动之前需要先启动Hadoop   脚本: start-all.sh</span><br><span class="line">hive</span><br></pre></td></tr></table></figure>
<img src="/2022/11/12/Hadoop-%C2%A9-pepsi-wyl/1667909857211-0e2ac56e-1098-4705-aae7-f466554528c6.png" class=""> 

<h2 id="基本操作"><a href="#基本操作" class="headerlink" title="基本操作"></a>基本操作</h2><h3 id="创建数据库、表、视图"><a href="#创建数据库、表、视图" class="headerlink" title="创建数据库、表、视图"></a>创建数据库、表、视图</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"># 创建数据库hive</span><br><span class="line">create database if not exists hive;</span><br><span class="line"></span><br><span class="line"># 创建表</span><br><span class="line">use hive;</span><br><span class="line">create table if not exists usr(id bigint,name string,age int);</span><br><span class="line">create table if not exists hive.usr(id bigint,name string,age int) location &#x27;/usr/local/hive/warehouse/hive/usr&#x27;;</span><br><span class="line">create table if not exists usr1 like usr;</span><br><span class="line"></span><br><span class="line"># 创建视图</span><br><span class="line">create view little_usr as select id,age from usr;</span><br></pre></td></tr></table></figure>

<h3 id="删除数据库、表、视图"><a href="#删除数据库、表、视图" class="headerlink" title="删除数据库、表、视图"></a>删除数据库、表、视图</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"># 删除数据库</span><br><span class="line">drop database if not exists hive;</span><br><span class="line">drop database if not exists hive cascade;</span><br><span class="line"></span><br><span class="line"># 删除表</span><br><span class="line">drop table if exists usr;</span><br><span class="line"></span><br><span class="line"># 删除视图</span><br><span class="line">drop view if exists little_usr;</span><br></pre></td></tr></table></figure>

<h3 id="修改数据库、表、视图"><a href="#修改数据库、表、视图" class="headerlink" title="修改数据库、表、视图"></a>修改数据库、表、视图</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"># 修改数据库</span><br><span class="line">alter database hive set dbproperties(&#x27;edited-by&#x27;=&#x27;lily&#x27;);</span><br><span class="line"></span><br><span class="line"># 修改表</span><br><span class="line">alter table usr rename to user;</span><br><span class="line">alter table usr add if not exists partition(age=10);</span><br><span class="line">alter table usr drop if exists partition(age=10);</span><br><span class="line">alter table usr change name username string after age;</span><br><span class="line">alter table usr add columns(sex boolean);</span><br><span class="line">alter table usr replace columns(newid bigint,newname string,newage int);</span><br><span class="line">alter table usr set tabproperties(‘notes’=’the columns in usr may be null except id’);</span><br><span class="line"></span><br><span class="line"># 修改视图</span><br><span class="line">alter view little_usr set tabproperties(‘create_at’=’refer to timestamp’);</span><br></pre></td></tr></table></figure>

<h3 id="查看数据库、表、视图"><a href="#查看数据库、表、视图" class="headerlink" title="查看数据库、表、视图"></a>查看数据库、表、视图</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"># 查看数据库</span><br><span class="line">show databases;</span><br><span class="line"></span><br><span class="line"># 查看表和视图</span><br><span class="line">use hive;</span><br><span class="line">show tables;</span><br></pre></td></tr></table></figure>

<h3 id="描述数据库、表、视图"><a href="#描述数据库、表、视图" class="headerlink" title="描述数据库、表、视图"></a>描述数据库、表、视图</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"># 描述数据库</span><br><span class="line">describe database hive;</span><br><span class="line">describe database extended hive;</span><br><span class="line"></span><br><span class="line"># 描述表和视图</span><br><span class="line">describe hive.usr;</span><br><span class="line">describe hive.little_usr;</span><br><span class="line">describe extended hive.usr;</span><br><span class="line">describe extended hive.little_usr;</span><br></pre></td></tr></table></figure>

<h3 id="向表中装载数据"><a href="#向表中装载数据" class="headerlink" title="向表中装载数据"></a>向表中装载数据</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"># 把目录&#x27;/usr/local/data&#x27;下的数据文件中的数据装载进usr表并覆盖原有数据</span><br><span class="line">load data local inpath &#x27;/usr/local/data&#x27; overwrite into table usr;</span><br><span class="line"></span><br><span class="line"># 把目录&#x27;/usr/local/data&#x27;下的数据文件中的数据装载进usr表不覆盖原有数据</span><br><span class="line">load data local inpath &#x27;/usr/local/data&#x27; into table usr;</span><br></pre></td></tr></table></figure>

<h3 id="向表中插入数据或从表中导出数据"><a href="#向表中插入数据或从表中导出数据" class="headerlink" title="向表中插入数据或从表中导出数据"></a>向表中插入数据或从表中导出数据</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"># 向表usr1中插入来自usr表的数据并覆盖原有数据</span><br><span class="line">insert overwrite table usr1 select * from usr where age=10;</span><br><span class="line"></span><br><span class="line"># 向表usr1中插入来自usr表的数据并追加在原有数据后</span><br><span class="line">insert into table usr1 select * from usr where age=10;</span><br></pre></td></tr></table></figure>

<h2 id="应用举例"><a href="#应用举例" class="headerlink" title="应用举例"></a>应用举例</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"># 创建处理的HDFS路径</span><br><span class="line">hadoop fs -mkdir /user/root/input</span><br><span class="line"></span><br><span class="line">cd /opt</span><br><span class="line">echo &quot;hello world&quot; &gt; file1.txt</span><br><span class="line">echo &quot;hello hadoop&quot; &gt; file2.txt</span><br><span class="line"></span><br><span class="line"># 上传</span><br><span class="line">hadoop fs -put file1.txt   /user/root/input</span><br><span class="line">hadoop fs -put file2.txt   /user/root/input</span><br><span class="line"></span><br><span class="line"># 删除本地文件</span><br><span class="line">rm -rf file1.txt file2.txt</span><br></pre></td></tr></table></figure>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"># 启动Hive</span><br><span class="line">hive</span><br><span class="line"></span><br><span class="line"># 创建输入表</span><br><span class="line">create table if not exists docs(line string);</span><br><span class="line"></span><br><span class="line"># 删除输出表</span><br><span class="line">drop table if exists word_count;</span><br><span class="line"></span><br><span class="line"># 加载数据</span><br><span class="line">load data inpath &#x27;input&#x27; overwrite into table docs;</span><br><span class="line"></span><br><span class="line"># 查看加载的数据</span><br><span class="line">select * from docs;</span><br><span class="line"></span><br><span class="line"># 开始分析</span><br><span class="line">create table word_count as </span><br><span class="line">      select word, count(1) as count from</span><br><span class="line">      (select explode(split(line,&#x27; &#x27;))as word from docs) w</span><br><span class="line">      group by word</span><br><span class="line">      order by word;</span><br><span class="line"></span><br><span class="line"># 查询结果</span><br><span class="line">select * from word_count;</span><br></pre></td></tr></table></figure>
<img src="/2022/11/12/Hadoop-%C2%A9-pepsi-wyl/1667913486795-4aec8db7-931a-482f-87cb-cab9cddf87ca.png" class=""> 
<img src="/2022/11/12/Hadoop-%C2%A9-pepsi-wyl/1667913441540-8b7eac86-5f98-44cb-938d-d1f40114b6c7.png" class=""> 

<h1 id="Pig技术"><a href="#Pig技术" class="headerlink" title="Pig技术"></a>Pig技术</h1><h2 id="安装Pig"><a href="#安装Pig" class="headerlink" title="安装Pig"></a>安装Pig</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"># 切换目录</span><br><span class="line">cd /opt</span><br><span class="line"> </span><br><span class="line"># 下载安装包  网址: https://dlcdn.apache.org/pig/</span><br><span class="line">wget https://dlcdn.apache.org/pig/pig-0.17.0/pig-0.17.0.tar.gz</span><br><span class="line"></span><br><span class="line"># 解压</span><br><span class="line">tar -zxvf pig-0.17.0.tar.gz </span><br><span class="line"></span><br><span class="line"># 重命名</span><br><span class="line">mv pig-0.17.0 pig</span><br><span class="line"></span><br><span class="line"># 删除安装包</span><br><span class="line">rm -rf pig-0.17.0.tar.gz</span><br><span class="line"></span><br><span class="line"># 添加环境变量</span><br><span class="line">vim /etc/profile</span><br><span class="line">#pig安装目录</span><br><span class="line">export PIG_HOME=/opt/pig  </span><br><span class="line">export PATH=$PATH:$PIG_HOME/bin</span><br><span class="line"># 更新环境变量</span><br><span class="line">source /etc/profile</span><br></pre></td></tr></table></figure>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"># 检测pig版本</span><br><span class="line">pig -version</span><br></pre></td></tr></table></figure>
<img src="/2022/11/12/Hadoop-%C2%A9-pepsi-wyl/1668686153223-7d2d73bb-e4c1-4ba7-8f23-fe32a7fe46e9.png" class="">
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"># 检测pig是否安装成功</span><br><span class="line">测试是否安装成功，使用pig命令进入，然后使用sh ls查看测试，能和增长运行表示成功。</span><br></pre></td></tr></table></figure>
<img src="/2022/11/12/Hadoop-%C2%A9-pepsi-wyl/1668935309710-da7cdbff-8fd8-4c47-b2c7-ebe0431cf00e.png" class="">
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"># 本地模式</span><br><span class="line">pig -x local</span><br></pre></td></tr></table></figure>
<img src="/2022/11/12/Hadoop-%C2%A9-pepsi-wyl/1668686235957-e09133e4-e46a-4faa-875e-c1a541e73cee.png" class="">
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"># MapReduce模式</span><br><span class="line">pig -x mapreduce</span><br></pre></td></tr></table></figure>
<img src="/2022/11/12/Hadoop-%C2%A9-pepsi-wyl/1668686259504-d4062bf4-3050-49ea-adce-ee359f6fef84.png" class="">

<h2 id="实验操作"><a href="#实验操作" class="headerlink" title="实验操作"></a>实验操作</h2><h3 id="创建文件并上传HDFS"><a href="#创建文件并上传HDFS" class="headerlink" title="创建文件并上传HDFS"></a>创建文件并上传HDFS</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br></pre></td><td class="code"><pre><span class="line"># 切换路径</span><br><span class="line">cd /opt</span><br><span class="line"></span><br><span class="line"># 创建文件</span><br><span class="line">vim student.txt</span><br><span class="line">201000101:李勇:男:20:计算机软件及理论</span><br><span class="line">201000102:王丽:女:19:计算机软件及理论</span><br><span class="line">201000103:刘花:女:18:计算机应用技术</span><br><span class="line">201000104:李肖:男:19:计算机系统结构</span><br><span class="line">201000105:浩达:男:19:计算机系统结构</span><br><span class="line">201000106:华克:男:19:计算机系统结构</span><br><span class="line"></span><br><span class="line"># 创建文件</span><br><span class="line">vim course.txt</span><br><span class="line">01,English,4</span><br><span class="line">02,Data Structure,2</span><br><span class="line">03,DataBase,2</span><br><span class="line">04,DB Design,3</span><br><span class="line">05,C Language,3</span><br><span class="line">06,Principles of Network,3</span><br><span class="line">07,OS,3</span><br><span class="line"></span><br><span class="line"># 创建文件</span><br><span class="line">vim sc.txt</span><br><span class="line">201000101,01,92</span><br><span class="line">201000101,03,84</span><br><span class="line">201000102,01,90</span><br><span class="line">201000102,02,94</span><br><span class="line">201000102,03,82</span><br><span class="line">201000103,01,72</span><br><span class="line">201000103,02,90</span><br><span class="line">201000104,03,75</span><br><span class="line"></span><br><span class="line"># 创建pig目录，专门存放这三个文件</span><br><span class="line">hdfs dfs -mkdir /pig_test</span><br><span class="line"></span><br><span class="line"># 上传文件</span><br><span class="line">hdfs dfs -put student.txt /pig_test</span><br><span class="line">hdfs dfs -put course.txt /pig_test</span><br><span class="line">hdfs dfs -put sc.txt /pig_test</span><br><span class="line"></span><br><span class="line"># 删除本地文件</span><br><span class="line">rm -rf student.txt;</span><br><span class="line">rm -rf course.txt;</span><br><span class="line">rm -rf sc.txt;</span><br></pre></td></tr></table></figure>
<img src="/2022/11/12/Hadoop-%C2%A9-pepsi-wyl/1668936075094-de112816-47ff-4316-9877-f386541a1627.png" class="">

<h3 id="实验操作-1"><a href="#实验操作-1" class="headerlink" title="实验操作"></a>实验操作</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">-&gt;pig</span><br><span class="line"></span><br><span class="line"># 在Pig加载数据</span><br><span class="line">a = load &#x27;/pig_test/student.txt&#x27; using PigStorage(&#x27;:&#x27;) as (sno:chararray,sname:chararray,sex:chararray,age:int,dept:chararray);</span><br><span class="line">b = load &#x27;/pig_test/course.txt&#x27; using PigStorage(&#x27;,&#x27;) as (cno:chararray,cname:chararray,grade:chararray);</span><br><span class="line">c = load &#x27;/pig_test/sc.txt&#x27; using PigStorage(&#x27;,&#x27;) as (sno:chararray,cno:chararray,score:float);</span><br><span class="line"></span><br><span class="line">a_join_c = join a by sno,c by sno;</span><br><span class="line">dump a_join_c;</span><br><span class="line"></span><br><span class="line">abc_join = join b by cno,a_join_c by c::cno;</span><br><span class="line">dump abc_join;</span><br><span class="line"></span><br><span class="line">not_excl = filter abc_join by score&lt;80;</span><br><span class="line">dump not_excl;</span><br><span class="line"></span><br><span class="line">foreach_data = foreach not_excl generate sname,cname,score;</span><br><span class="line">dump foreach_data;</span><br></pre></td></tr></table></figure>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">在hadoop集群上运行pig报如下错误：报错INFO  org.apache.hadoop.ipc.Client - Retrying connect to server: 0.0.0.0/0.0.0.0:10020. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)</span><br><span class="line"></span><br><span class="line">解决方案：启动historyserver：</span><br><span class="line">mapred --daemon start historyserver</span><br></pre></td></tr></table></figure>
<img src="/2022/11/12/Hadoop-%C2%A9-pepsi-wyl/1668942481278-04ea5f0e-5698-4feb-a45d-8787820010e6.png" class="">
<img src="/2022/11/12/Hadoop-%C2%A9-pepsi-wyl/1668943741931-e2f05310-6903-4306-8dd0-9b7d433c22d1.png" class="">
<img src="/2022/11/12/Hadoop-%C2%A9-pepsi-wyl/1668943809574-5a35ec1d-1ac6-4766-b2b5-5c4a4316b4d2.png" class="">
<img src="/2022/11/12/Hadoop-%C2%A9-pepsi-wyl/1668943945695-0b9788b6-bfc7-43ed-b16c-6203f0fc198e.png" class="">

<h1 id="Sqoop技术"><a href="#Sqoop技术" class="headerlink" title="Sqoop技术"></a>Sqoop技术</h1><h2 id="安装Sqoop"><a href="#安装Sqoop" class="headerlink" title="安装Sqoop"></a>安装Sqoop</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"># 切换目录</span><br><span class="line">cd /opt</span><br><span class="line"> </span><br><span class="line"># 下载安装包  网址:https://archive.apache.org/dist/sqoop/</span><br><span class="line">wget https://archive.apache.org/dist/sqoop/1.4.7/sqoop-1.4.7.bin__hadoop-2.6.0.tar.gz</span><br><span class="line"></span><br><span class="line"># 解压</span><br><span class="line">tar -zxvf sqoop-1.4.7.bin__hadoop-2.6.0.tar.gz </span><br><span class="line"></span><br><span class="line"># 重命名</span><br><span class="line">mv sqoop-1.4.7.bin__hadoop-2.6.0 sqoop</span><br><span class="line"></span><br><span class="line"># 配置环境变量</span><br><span class="line">vim /etc/profile</span><br><span class="line"># sqoop安装目录</span><br><span class="line">export SQOOP_HOME=/opt/sqoop</span><br><span class="line">export PATH=$PATH:$SQOOP_HOME/bin</span><br><span class="line">export CLASSPATH=$CLASSPATH:$SQOOP_HOME/lib</span><br><span class="line"># 更新环境变量</span><br><span class="line">source /etc/profile</span><br><span class="line"></span><br><span class="line"># 删除安装包</span><br><span class="line">rm -rf sqoop-1.4.7.bin__hadoop-2.6.0.tar.gz</span><br></pre></td></tr></table></figure>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"># 重写命名配置文件</span><br><span class="line">mv /opt/sqoop/conf/sqoop-env-template.sh  /opt/sqoop/conf/sqoop-env.sh</span><br><span class="line"></span><br><span class="line"># 配置sqoop-env.sh文件</span><br><span class="line">vim sqoop-env.sh</span><br><span class="line">插入</span><br><span class="line">export HADOOP_COMMON_HOME=/home/hadoop/hadoop</span><br><span class="line">export HADOOP_MAPRED_HOME=/home/hadoop/hadoop</span><br><span class="line">export HIVE_HOME=/opt/hive</span><br><span class="line">export HIVE_CONF_DIR=//opt/hive/conf</span><br></pre></td></tr></table></figure>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"># 拷贝mysql驱动</span><br><span class="line">cp /opt/hive/lib/mysql-connector-java.jar /opt/sqoop/lib</span><br></pre></td></tr></table></figure>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"># 测试连接数据库</span><br><span class="line">sqoop list-databases --connect jdbc:mysql://127.0.0.1:3306/ --username root -P</span><br><span class="line">-&gt;输入密码......</span><br></pre></td></tr></table></figure>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">解决BUG报错 Exception in thread &quot;main&quot; java.lang.NoClassDefFoundError: org/apache/commons/lang/StringUtils</span><br><span class="line">cd /opt</span><br><span class="line">wget https://mirrors.tuna.tsinghua.edu.cn/apache//commons/lang/binaries/commons-lang-2.6-bin.tar.gz</span><br><span class="line">tar -zxvf commons-lang-2.6-bin.tar.gz </span><br><span class="line">cp /opt/commons-lang-2.6/commons-lang-2.6.jar /opt/sqoop/lib</span><br><span class="line">rm -rf commons-lang-2.6-bin.tar.gz</span><br><span class="line">rm -rf commons-lang-2.6</span><br></pre></td></tr></table></figure>
<img src="/2022/11/12/Hadoop-%C2%A9-pepsi-wyl/1668946680916-fcf23f2b-e7a9-4a1f-b8ba-b88f8021e970.png" class="">

<h2 id="实验操作-2"><a href="#实验操作-2" class="headerlink" title="实验操作"></a>实验操作</h2><h3 id="创建数据文件"><a href="#创建数据文件" class="headerlink" title="创建数据文件"></a>创建数据文件</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br></pre></td><td class="code"><pre><span class="line">drop database if exists userdb;</span><br><span class="line">create database userdb;</span><br><span class="line">use userdb;</span><br><span class="line">drop table if exists emp;</span><br><span class="line">drop table if exists emp_add;</span><br><span class="line">drop table if exists emp_conn;</span><br><span class="line"> </span><br><span class="line">CREATE TABLE emp(</span><br><span class="line">	id INT NOT NULL,</span><br><span class="line">	name VARCHAR(100),</span><br><span class="line">	deg VARCHAR(100),</span><br><span class="line">	salary BIGINT,</span><br><span class="line">	dept VARCHAR(50)</span><br><span class="line">);</span><br><span class="line"> </span><br><span class="line">CREATE TABLE emp_add(</span><br><span class="line">	id INT NOT NULL,</span><br><span class="line">	hno VARCHAR(50),</span><br><span class="line">	street VARCHAR(50),</span><br><span class="line">	city VARCHAR(50)</span><br><span class="line">);</span><br><span class="line"> </span><br><span class="line">CREATE TABLE emp_conn(</span><br><span class="line">	id INT NOT NULL,</span><br><span class="line">	phno VARCHAR(50),</span><br><span class="line">	email VARCHAR(50)</span><br><span class="line">);</span><br><span class="line"> </span><br><span class="line">insert into emp values(1201,&#x27;gopal&#x27;,&#x27;manager&#x27;,&#x27;50000&#x27;,&#x27;TP&#x27;);</span><br><span class="line">insert into emp values(1202,&#x27;manisha&#x27;,&#x27;Proof reader&#x27;,&#x27;50000&#x27;,&#x27;TP&#x27;);</span><br><span class="line">insert into emp values(1204,&#x27;prasanth&#x27;,&#x27;php dev&#x27;,&#x27;30000&#x27;,&#x27;AC&#x27;);</span><br><span class="line">insert into emp values(1205,&#x27;kranthi&#x27;,&#x27;admin&#x27;,&#x27;20000&#x27;,&#x27;TP&#x27;);</span><br><span class="line"> </span><br><span class="line">insert into emp_add values(1201,&#x27;288A&#x27;,&#x27;vgiri&#x27;,&#x27;jublee&#x27;);</span><br><span class="line">insert into emp_add values(1202,&#x27;108I&#x27;,&#x27;aoc&#x27;,&#x27;sec-bad&#x27;);</span><br><span class="line">insert into emp_add values(1203,&#x27;144Z&#x27;,&#x27;pgutta&#x27;,&#x27;hyd&#x27;);</span><br><span class="line">insert into emp_add values(1204,&#x27;78B&#x27;,&#x27;old city&#x27;,&#x27;sec-bad&#x27;);</span><br><span class="line">insert into emp_add values(1205,&#x27;720X&#x27;,&#x27;hitec&#x27;,&#x27;sec-bad&#x27;);</span><br><span class="line"> </span><br><span class="line">insert into emp_conn values(1201,&#x27;2356742&#x27;,&#x27;gopal@tp.com&#x27;);</span><br><span class="line">insert into emp_conn values(1202,&#x27;1661663&#x27;,&#x27;manisha@tp.com&#x27;);</span><br><span class="line">insert into emp_conn values(1203,&#x27;8887776&#x27;,&#x27;khalil@ac.com&#x27;);</span><br><span class="line">insert into emp_conn values(1204,&#x27;9988774&#x27;,&#x27;prasanth@ac.com&#x27;);</span><br><span class="line">insert into emp_conn values(1205,&#x27;1231231&#x27;,&#x27;kranthi@tp.com&#x27;);</span><br></pre></td></tr></table></figure>
<img src="/2022/11/12/Hadoop-%C2%A9-pepsi-wyl/1668947371652-f8019f76-3efc-4869-9b98-2448477b2e6f.png" class="">

<h3 id="Sqoop的数据导入"><a href="#Sqoop的数据导入" class="headerlink" title="Sqoop的数据导入"></a><strong>Sqoop的数据导入</strong></h3><h4 id="导入HDFS中"><a href="#导入HDFS中" class="headerlink" title="导入HDFS中"></a>导入HDFS中</h4><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"># 导入</span><br><span class="line">hadoop fs -rm -r /user/root/emp;</span><br><span class="line">sqoop  import  --connect jdbc:mysql://192.168.131.144:3306/userdb  --username root  --password root  --table emp  --m 1; </span><br><span class="line"></span><br><span class="line"># 查看</span><br><span class="line">hadoop fs -cat /user/root/emp/part-m-00000</span><br></pre></td></tr></table></figure>
<img src="/2022/11/12/Hadoop-%C2%A9-pepsi-wyl/1668947907436-fa506eb1-da1b-44a4-8153-f3182bd381fd.png" class="">

<h4 id="导入HIVE中"><a href="#导入HIVE中" class="headerlink" title="导入HIVE中"></a>导入HIVE中</h4><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"># 导入HIVE的时，默认目录中不能有当前表</span><br><span class="line">hadoop fs -rm -r /user/root/emp;</span><br><span class="line"></span><br><span class="line"># 导入HIVE</span><br><span class="line">sqoop  import  --connect jdbc:mysql://192.168.131.144:3306/userdb  --username root  --password root  --table emp  --hive-import  --m 1; </span><br></pre></td></tr></table></figure>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">// ERROR tool.ImportTool: Import failed: java.io.IOException: java.lang.ClassNotFoundException: </span><br><span class="line">cp /opt/hive/lib/hive-common-3.1.2.jar /opt/sqoop/lib/</span><br><span class="line">cp /opt/hive/lib/hive-exec-3.1.2.jar /opt/sqoop/lib/</span><br></pre></td></tr></table></figure>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">-&gt;hive</span><br><span class="line">select * from emp;</span><br></pre></td></tr></table></figure>
<img src="/2022/11/12/Hadoop-%C2%A9-pepsi-wyl/1668948884923-d27814f1-0c04-41ff-b391-646e16222c64.png" class="">

<h4 id="导入表数据子集"><a href="#导入表数据子集" class="headerlink" title="导入表数据子集"></a>导入表数据子集</h4><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"># 导入</span><br><span class="line">hadoop fs -rm -r /wherequery;</span><br><span class="line">sqoop  import  --connect jdbc:mysql://192.168.131.144:3306/userdb  --username root  --password root  --target-dir /wherequery  --query &#x27;select id,name,deg from emp WHERE id&gt;1203 and $CONDITIONS&#x27;  --split-by id  --fields-terminated-by &#x27;\t&#x27;  --m 1;</span><br><span class="line"></span><br><span class="line"># 查看</span><br><span class="line">hadoop fs -cat /wherequery/part-m-*</span><br></pre></td></tr></table></figure>
<img src="/2022/11/12/Hadoop-%C2%A9-pepsi-wyl/1668949339913-4cea7b6a-633b-4518-b9a5-67f570329997.png" class="">

<h3 id="Sqoop的数据导出"><a href="#Sqoop的数据导出" class="headerlink" title="Sqoop的数据导出"></a>Sqoop的数据导出</h3><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">use userdb;</span><br><span class="line"><span class="keyword">drop</span> <span class="keyword">table</span> if <span class="keyword">exists</span> employee;</span><br><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> if <span class="keyword">not</span> <span class="keyword">exists</span> employee ( </span><br><span class="line">  id <span class="type">INT</span> <span class="keyword">NOT</span> <span class="keyword">NULL</span> <span class="keyword">PRIMARY</span> KEY, </span><br><span class="line">  name <span class="type">VARCHAR</span>(<span class="number">20</span>), </span><br><span class="line">  deg <span class="type">VARCHAR</span>(<span class="number">20</span>),</span><br><span class="line">  salary <span class="type">INT</span>,</span><br><span class="line">  dept <span class="type">VARCHAR</span>(<span class="number">10</span>));</span><br></pre></td></tr></table></figure>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"># 导出</span><br><span class="line">sqoop  export   --connect jdbc:mysql://192.168.131.144:3306/userdb  --username root  --password root  --table employee --export-dir /user/root/emp;</span><br></pre></td></tr></table></figure>
<img src="/2022/11/12/Hadoop-%C2%A9-pepsi-wyl/1668950327042-d47f5296-706f-4182-8423-76b0737ab88f.png" class=""></article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta">文章作者: </span><span class="post-copyright-info"><a href="https://ylan.site">pepsi-wyl</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta">文章链接: </span><span class="post-copyright-info"><a href="https://ylan.site/2022/11/12/Hadoop-%C2%A9-pepsi-wyl/">https://ylan.site/2022/11/12/Hadoop-%C2%A9-pepsi-wyl/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta">版权声明: </span><span class="post-copyright-info">本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank">CC BY-NC-SA 4.0</a> 许可协议。转载请注明来自 <a href="https://ylan.site" target="_blank">伤寒杂病论 by pepsi-wyl</a>！</span></div></div><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/Hadoop/">Hadoop</a><a class="post-meta__tags" href="/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/">大数据</a></div><div class="post_share"><div class="social-share" data-image="/img/bg/bg7.jpg" data-sites="wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/css/share.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/js/social-share.min.js" defer></script></div></div><nav class="pagination-post" id="pagination"><div class="prev-post pull-left"><a href="/2022/11/16/EasyExcel-%C2%A9-pepsi-wyl/"><img class="prev-cover" src="/img/bg/bg6.jpg" onerror="onerror=null;src='/img/404.jpg'" alt="cover of previous post"><div class="pagination-info"><div class="label">上一篇</div><div class="prev_info">EasyExcel © pepsi-wyl</div></div></a></div><div class="next-post pull-right"><a href="/2022/11/12/Hexo/"><img class="next-cover" src="/img/bg/bg8.jpg" onerror="onerror=null;src='/img/404.jpg'" alt="cover of next post"><div class="pagination-info"><div class="label">下一篇</div><div class="next_info">Hexo入门</div></div></a></div></nav></div><div class="aside-content" id="aside-content"><div class="card-widget card-info"><div class="is-center"><div class="avatar-img"><img src="/img/ava.jpg" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/></div><div class="author-info__name">pepsi-wyl</div><div class="author-info__description">多看报，多睡觉</div></div><div class="card-info-data site-data is-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">11</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">11</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">7</div></a></div><a id="card-info-btn" target="_blank" rel="noopener" href="https://github.com/pepsi-wyl/pepsi-wyl.github.io"><i class="fab fa-github"></i><span>博客仓库地址</span></a><div class="card-info-social-icons is-center"><a class="social-icon" href="https://github.com/pepsi-wyl" target="_blank" title="Github"><i class="fab fa-github"></i></a></div></div><div class="card-widget card-announcement"><div class="item-headline"><i class="fas fa-bullhorn fa-shake"></i><span>公告</span></div><div class="announcement_content">仰天大笑出门去，我辈岂是蓬蒿人。</div><timing></timing></div><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>目录</span><span class="toc-percentage"></span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#Hadoop%E7%AE%80%E4%BB%8B"><span class="toc-number">1.</span> <span class="toc-text">Hadoop简介</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E5%8D%95%E6%9C%BA%E5%AE%89%E8%A3%85"><span class="toc-number">2.</span> <span class="toc-text">单机安装</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E9%A2%84%E5%85%88%E9%85%8D%E7%BD%AE"><span class="toc-number">2.1.</span> <span class="toc-text">预先配置</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%85%B3%E9%97%AD%E9%98%B2%E7%81%AB%E5%A2%99"><span class="toc-number">2.1.1.</span> <span class="toc-text">关闭防火墙</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%BF%AE%E6%94%B9%E4%B8%BB%E6%9C%BA%E5%90%8D%E7%A7%B0%E5%92%8C%E6%B7%BB%E5%8A%A0%E6%98%A0%E5%B0%84"><span class="toc-number">2.1.2.</span> <span class="toc-text">修改主机名称和添加映射</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%88%9B%E5%BB%BAHadoop%E7%94%A8%E6%88%B7"><span class="toc-number">2.1.3.</span> <span class="toc-text">创建Hadoop用户</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E8%AE%BE%E7%BD%AESSH%E5%85%8D%E5%AF%86%E7%99%BB%E9%99%86"><span class="toc-number">2.1.4.</span> <span class="toc-text">设置SSH免密登陆</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%AE%89%E8%A3%85JAVA%E5%B9%B6%E9%85%8D%E7%BD%AE%E7%8E%AF%E5%A2%83%E5%8F%98%E9%87%8F"><span class="toc-number">2.1.5.</span> <span class="toc-text">安装JAVA并配置环境变量</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%AE%89%E8%A3%85Hadoop%E5%B9%B6%E9%85%8D%E7%BD%AE%E7%8E%AF%E5%A2%83%E5%8F%98%E9%87%8F"><span class="toc-number">2.1.6.</span> <span class="toc-text">安装Hadoop并配置环境变量</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%8D%95%E6%9C%BA%E9%9D%9E%E5%88%86%E5%B8%83%E5%BC%8F%E8%BF%90%E8%A1%8C"><span class="toc-number">2.2.</span> <span class="toc-text">单机非分布式运行</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%BC%AA%E5%88%86%E5%B8%83%E5%BC%8F%E8%BF%90%E8%A1%8C"><span class="toc-number">2.3.</span> <span class="toc-text">伪分布式运行</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%88%9B%E5%BB%BAhadoop%E5%AD%98%E6%94%BE%E6%95%B0%E6%8D%AE%E7%9A%84%E7%9B%AE%E5%BD%95"><span class="toc-number">2.3.1.</span> <span class="toc-text">创建hadoop存放数据的目录</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%BF%AE%E6%94%B9%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6"><span class="toc-number">2.3.2.</span> <span class="toc-text">修改配置文件</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%BF%AE%E6%94%B9%E7%8E%AF%E5%A2%83%E5%8F%98%E9%87%8F"><span class="toc-number">2.3.3.</span> <span class="toc-text">修改环境变量</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%A0%BC%E5%BC%8F%E5%8C%96%E9%9B%86%E7%BE%A4%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F"><span class="toc-number">2.3.4.</span> <span class="toc-text">格式化集群文件系统</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%90%AF%E5%8A%A8%E4%BC%AA%E5%88%86%E5%B8%83%E5%BC%8F"><span class="toc-number">2.3.5.</span> <span class="toc-text">启动伪分布式</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Web%E7%AE%A1%E7%90%86%E7%95%8C%E9%9D%A2%EF%BC%88%E5%85%B3%E9%97%AD%E9%98%B2%E7%81%AB%E5%A2%99%E6%88%96%E8%80%85%E6%94%BE%E8%A1%8C%E7%AB%AF%E5%8F%A3%EF%BC%89"><span class="toc-number">2.3.6.</span> <span class="toc-text">Web管理界面（关闭防火墙或者放行端口）</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%85%B3%E9%97%AD%E4%BC%AA%E5%88%86%E5%B8%83%E5%BC%8F"><span class="toc-number">2.3.7.</span> <span class="toc-text">关闭伪分布式</span></a></li></ol></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E5%88%86%E5%B8%83%E5%BC%8F%E5%AE%89%E8%A3%85-%E9%80%89%E4%BD%9C"><span class="toc-number">3.</span> <span class="toc-text">分布式安装(选作)</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E8%99%9A%E6%9C%BA%E5%88%86%E9%85%8D"><span class="toc-number">3.1.</span> <span class="toc-text">虚机分配</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%87%86%E5%A4%87%E5%B7%A5%E4%BD%9C"><span class="toc-number">3.2.</span> <span class="toc-text">准备工作</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%85%B3%E9%97%AD%E9%98%B2%E7%81%AB%E5%A2%99-3%E5%8F%B0"><span class="toc-number">3.2.1.</span> <span class="toc-text">关闭防火墙(3台)</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%BF%AE%E6%94%B9%E4%B8%BB%E6%9C%BA%E5%90%8D%E7%A7%B0%E5%92%8C%E4%BF%AE%E6%94%B9%E6%98%A0%E5%B0%84-3%E5%8F%B0"><span class="toc-number">3.2.2.</span> <span class="toc-text">修改主机名称和修改映射(3台)</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E8%AE%BE%E7%BD%AESSH%E5%85%8D%E5%AF%86%E7%99%BB%E9%99%86-3%E5%8F%B0"><span class="toc-number">3.2.3.</span> <span class="toc-text">设置SSH免密登陆(3台)</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%AE%89%E8%A3%85JDK%E5%B9%B6%E9%85%8D%E7%BD%AE%E7%8E%AF%E5%A2%83%E5%8F%98%E9%87%8F-3%E5%8F%B0"><span class="toc-number">3.2.4.</span> <span class="toc-text">安装JDK并配置环境变量(3台)</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%AE%89%E8%A3%85Hadoop%E5%B9%B6%E9%85%8D%E7%BD%AE%E7%8E%AF%E5%A2%83%E5%8F%98%E9%87%8F-3%E5%8F%B0"><span class="toc-number">3.2.5.</span> <span class="toc-text">安装Hadoop并配置环境变量(3台)</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%BF%AE%E6%94%B9%E7%8E%AF%E5%A2%83%E5%8F%98%E9%87%8F-3%E5%8F%B0"><span class="toc-number">3.3.</span> <span class="toc-text">修改环境变量(3台)</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%BF%AE%E6%94%B9%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6-3%E5%8F%B0"><span class="toc-number">3.4.</span> <span class="toc-text">修改配置文件(3台)</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%A0%BC%E5%BC%8F%E5%8C%96%E9%9B%86%E7%BE%A4%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F-3%E5%8F%B0"><span class="toc-number">3.5.</span> <span class="toc-text">格式化集群文件系统(3台)</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%90%AF%E5%8A%A8%E5%88%86%E5%B8%83%E5%BC%8F%E9%9B%86%E7%BE%A4-3%E5%8F%B0"><span class="toc-number">3.6.</span> <span class="toc-text">启动分布式集群(3台)</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Web%E7%AE%A1%E7%90%86%E7%95%8C%E9%9D%A2%EF%BC%88%E5%85%B3%E9%97%AD%E9%98%B2%E7%81%AB%E5%A2%99%E6%88%96%E8%80%85%E6%94%BE%E8%A1%8C%E7%AB%AF%E5%8F%A3%EF%BC%89-1"><span class="toc-number">3.7.</span> <span class="toc-text">Web管理界面（关闭防火墙或者放行端口）</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%85%B3%E9%97%AD%E5%88%86%E5%B8%83%E5%BC%8F%E9%9B%86%E7%BE%A4-3%E5%8F%B0"><span class="toc-number">3.8.</span> <span class="toc-text">关闭分布式集群(3台)</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E6%96%87%E4%BB%B6%E7%9A%84%E6%93%8D%E4%BD%9C%E7%BB%BC%E5%90%88%E5%BA%94%E7%94%A8"><span class="toc-number">4.</span> <span class="toc-text">文件的操作综合应用</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%91%BD%E4%BB%A4%E8%A1%8C%E6%93%8D%E4%BD%9C"><span class="toc-number">4.1.</span> <span class="toc-text">命令行操作</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#HDFS-API%E7%BC%96%E7%A8%8B"><span class="toc-number">4.2.</span> <span class="toc-text">HDFS API编程</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#MapReduce%E5%9F%BA%E7%A1%80%E7%BC%96%E7%A8%8B"><span class="toc-number">5.</span> <span class="toc-text">MapReduce基础编程</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%BD%BF%E7%94%A8%E5%91%BD%E4%BB%A4%E8%A1%8C%E7%BC%96%E8%AF%91%E6%89%93%E5%8C%85%E8%AF%8D%E9%A2%91%E7%BB%9F%E8%AE%A1%E7%A8%8B%E5%BA%8F"><span class="toc-number">5.1.</span> <span class="toc-text">使用命令行编译打包词频统计程序</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#HDFS%E4%B8%AD%E5%88%9B%E5%BB%BA%E6%96%87%E4%BB%B6"><span class="toc-number">5.1.1.</span> <span class="toc-text">HDFS中创建文件</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%BC%96%E5%86%99%E6%BA%90%E6%96%87%E4%BB%B6"><span class="toc-number">5.1.2.</span> <span class="toc-text">编写源文件</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%BC%96%E8%AF%91%E6%89%93%E5%8C%85%E8%BF%90%E8%A1%8C"><span class="toc-number">5.1.3.</span> <span class="toc-text">编译打包运行</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%8E%92%E9%94%99"><span class="toc-number">5.1.4.</span> <span class="toc-text">排错</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%BD%BF%E7%94%A8Idea%E7%BC%96%E8%AF%91%E8%BF%90%E8%A1%8C%E8%AF%8D%E9%A2%91%E7%BB%9F%E8%AE%A1%E7%A8%8B%E5%BA%8F"><span class="toc-number">5.2.</span> <span class="toc-text">使用Idea编译运行词频统计程序</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#HDFS%E4%B8%AD%E5%88%9B%E5%BB%BA%E6%96%87%E4%BB%B6-1"><span class="toc-number">5.2.1.</span> <span class="toc-text">HDFS中创建文件</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#maven%E5%B7%A5%E7%A8%8B"><span class="toc-number">5.2.2.</span> <span class="toc-text">maven工程</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%88%9B%E5%BB%BA%E5%B7%A5%E7%A8%8B"><span class="toc-number">5.2.2.1.</span> <span class="toc-text">创建工程</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%AF%BC%E5%85%A5%E4%BE%9D%E8%B5%96"><span class="toc-number">5.2.2.2.</span> <span class="toc-text">导入依赖</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E7%BC%96%E5%86%99%E6%BA%90%E7%A0%81"><span class="toc-number">5.2.2.3.</span> <span class="toc-text">编写源码</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%89%93%E5%8C%85"><span class="toc-number">5.2.2.4.</span> <span class="toc-text">打包</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%B8%8A%E4%BC%A0%E6%9C%8D%E5%8A%A1%E5%99%A8%E8%BF%90%E8%A1%8C"><span class="toc-number">5.2.3.</span> <span class="toc-text">上传服务器运行</span></a></li></ol></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#HBase%E5%9F%BA%E6%9C%AC%E4%BD%BF%E7%94%A8"><span class="toc-number">6.</span> <span class="toc-text">HBase基本使用</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%AE%89%E8%A3%85"><span class="toc-number">6.1.</span> <span class="toc-text">安装</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%B8%8B%E8%BD%BD%E5%92%8C%E5%AE%89%E8%A3%85"><span class="toc-number">6.1.1.</span> <span class="toc-text">下载和安装</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E7%89%88%E6%9C%AC%E5%AF%B9%E5%BA%94%E5%85%B3%E7%B3%BB"><span class="toc-number">6.1.1.1.</span> <span class="toc-text">版本对应关系</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E4%B8%8B%E8%BD%BD%E5%92%8C%E8%A7%A3%E5%8E%8B"><span class="toc-number">6.1.1.2.</span> <span class="toc-text">下载和解压</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E9%85%8D%E7%BD%AE%E7%8E%AF%E5%A2%83%E5%8F%98%E9%87%8F"><span class="toc-number">6.1.1.3.</span> <span class="toc-text">配置环境变量</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%9F%A5%E7%9C%8BHBase%E7%89%88%E6%9C%AC%E4%BF%A1%E6%81%AF"><span class="toc-number">6.1.1.4.</span> <span class="toc-text">查看HBase版本信息</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E9%85%8D%E7%BD%AE"><span class="toc-number">6.1.2.</span> <span class="toc-text">配置</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E9%85%8D%E7%BD%AEhbase-env-sh"><span class="toc-number">6.1.2.1.</span> <span class="toc-text">配置hbase-env.sh</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E9%85%8D%E7%BD%AEhbase-site-xml"><span class="toc-number">6.1.2.2.</span> <span class="toc-text">配置hbase-site.xml</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%90%AF%E5%8A%A8%E5%92%8C%E5%81%9C%E6%AD%A2"><span class="toc-number">6.1.3.</span> <span class="toc-text">启动和停止</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Shell%E5%91%BD%E4%BB%A4"><span class="toc-number">6.2.</span> <span class="toc-text">Shell命令</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%90%AF%E5%8A%A8"><span class="toc-number">6.2.1.</span> <span class="toc-text">启动</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%88%9B%E5%BB%BA%E8%A1%A8"><span class="toc-number">6.2.2.</span> <span class="toc-text">创建表</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%88%A0%E9%99%A4%E8%A1%A8"><span class="toc-number">6.2.3.</span> <span class="toc-text">删除表</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%8F%92%E5%85%A5%E6%95%B0%E6%8D%AE"><span class="toc-number">6.2.4.</span> <span class="toc-text">插入数据</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%9F%A5%E7%9C%8B%E6%95%B0%E6%8D%AE"><span class="toc-number">6.2.5.</span> <span class="toc-text">查看数据</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%88%A0%E9%99%A4%E6%95%B0%E6%8D%AE"><span class="toc-number">6.2.6.</span> <span class="toc-text">删除数据</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%9F%A5%E8%AF%A2%E5%8E%86%E5%8F%B2%E6%95%B0%E6%8D%AE"><span class="toc-number">6.2.7.</span> <span class="toc-text">查询历史数据</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E9%80%80%E5%87%BA"><span class="toc-number">6.2.8.</span> <span class="toc-text">退出</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Idae%E7%BC%96%E7%A8%8B"><span class="toc-number">6.3.</span> <span class="toc-text">Idae编程</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#Windows%E6%B7%BB%E5%8A%A0%E6%98%A0%E5%B0%84"><span class="toc-number">6.3.1.</span> <span class="toc-text">Windows添加映射</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%88%9B%E5%BB%BAMaven%E5%B9%B6%E4%B8%94%E6%B7%BB%E5%8A%A0%E4%BE%9D%E8%B5%96"><span class="toc-number">6.3.2.</span> <span class="toc-text">创建Maven并且添加依赖</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%BC%96%E5%86%99%E4%BB%A3%E7%A0%81"><span class="toc-number">6.3.3.</span> <span class="toc-text">编写代码</span></a></li></ol></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#Zookeeper%E6%8A%80%E6%9C%AF"><span class="toc-number">7.</span> <span class="toc-text">Zookeeper技术</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%AE%89%E8%A3%85-1"><span class="toc-number">7.1.</span> <span class="toc-text">安装</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%8D%95%E6%9C%BA%E5%AE%89%E8%A3%85-1"><span class="toc-number">7.1.1.</span> <span class="toc-text">单机安装</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%BC%AA%E5%88%86%E5%B8%83%E5%BC%8F%E5%AE%89%E8%A3%85"><span class="toc-number">7.1.2.</span> <span class="toc-text">伪分布式安装</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%88%86%E5%B8%83%E5%BC%8F%E5%AE%89%E8%A3%85-%E9%80%89%E4%BD%9C-1"><span class="toc-number">7.1.3.</span> <span class="toc-text">分布式安装(选作)</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%93%8D%E4%BD%9C"><span class="toc-number">7.2.</span> <span class="toc-text">操作</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#0-%E5%90%AF%E5%8A%A8Cli"><span class="toc-number">7.2.1.</span> <span class="toc-text">0.启动Cli</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#1-%E5%88%9B%E5%BB%BAZnodes"><span class="toc-number">7.2.2.</span> <span class="toc-text">1.创建Znodes</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-%E8%8E%B7%E5%8F%96%E6%95%B0%E6%8D%AE"><span class="toc-number">7.2.3.</span> <span class="toc-text">2.获取数据</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3-Watch%EF%BC%88%E7%9B%91%E8%A7%86%EF%BC%89"><span class="toc-number">7.2.4.</span> <span class="toc-text">3.Watch（监视）</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#4-%E8%AE%BE%E7%BD%AE%E6%95%B0%E6%8D%AE"><span class="toc-number">7.2.5.</span> <span class="toc-text">4.设置数据</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#5-%E5%88%9B%E5%BB%BAznode%E5%AD%90%E8%8A%82%E7%82%B9"><span class="toc-number">7.2.6.</span> <span class="toc-text">5.创建znode子节点</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#6-%E5%88%97%E5%87%BAznode%E7%9A%84%E5%AD%90%E8%8A%82%E7%82%B9"><span class="toc-number">7.2.7.</span> <span class="toc-text">6.列出znode的子节点</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#7-%E6%A3%80%E6%9F%A5%E7%8A%B6%E6%80%81"><span class="toc-number">7.2.8.</span> <span class="toc-text">7.检查状态</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#8-%E5%88%A0%E9%99%A4Znode"><span class="toc-number">7.2.9.</span> <span class="toc-text">8. 删除Znode</span></a></li></ol></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E6%95%B0%E6%8D%AE%E4%BB%93%E5%BA%93Hive"><span class="toc-number">8.</span> <span class="toc-text">数据仓库Hive</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%AE%89%E8%A3%85-2"><span class="toc-number">8.1.</span> <span class="toc-text">安装</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%AE%89%E8%A3%85Mysql"><span class="toc-number">8.1.1.</span> <span class="toc-text">安装Mysql</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%AE%89%E8%A3%85Docker"><span class="toc-number">8.1.1.1.</span> <span class="toc-text">安装Docker</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%90%AF%E5%8A%A8Mysql%E5%AE%B9%E5%99%A8"><span class="toc-number">8.1.1.2.</span> <span class="toc-text">启动Mysql容器</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%88%9B%E5%BB%BAhive%E5%BA%93"><span class="toc-number">8.1.1.3.</span> <span class="toc-text">创建hive库</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%AE%89%E8%A3%85Hive"><span class="toc-number">8.1.2.</span> <span class="toc-text">安装Hive</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%AE%89%E8%A3%85-3"><span class="toc-number">8.1.2.1.</span> <span class="toc-text">安装</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%B7%BB%E5%8A%A0jar%E5%8C%85"><span class="toc-number">8.1.2.2.</span> <span class="toc-text">添加jar包</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E9%85%8D%E7%BD%AEHive"><span class="toc-number">8.1.2.3.</span> <span class="toc-text">配置Hive</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%89%A7%E8%A1%8C%E5%88%9D%E5%A7%8B%E5%8C%96%E5%91%BD%E4%BB%A4"><span class="toc-number">8.1.2.4.</span> <span class="toc-text">执行初始化命令</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#BUG"><span class="toc-number">8.1.2.4.1.</span> <span class="toc-text">BUG</span></a></li></ol></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%90%AF%E5%8A%A8-1"><span class="toc-number">8.1.2.5.</span> <span class="toc-text">启动</span></a></li></ol></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%9F%BA%E6%9C%AC%E6%93%8D%E4%BD%9C"><span class="toc-number">8.2.</span> <span class="toc-text">基本操作</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%88%9B%E5%BB%BA%E6%95%B0%E6%8D%AE%E5%BA%93%E3%80%81%E8%A1%A8%E3%80%81%E8%A7%86%E5%9B%BE"><span class="toc-number">8.2.1.</span> <span class="toc-text">创建数据库、表、视图</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%88%A0%E9%99%A4%E6%95%B0%E6%8D%AE%E5%BA%93%E3%80%81%E8%A1%A8%E3%80%81%E8%A7%86%E5%9B%BE"><span class="toc-number">8.2.2.</span> <span class="toc-text">删除数据库、表、视图</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%BF%AE%E6%94%B9%E6%95%B0%E6%8D%AE%E5%BA%93%E3%80%81%E8%A1%A8%E3%80%81%E8%A7%86%E5%9B%BE"><span class="toc-number">8.2.3.</span> <span class="toc-text">修改数据库、表、视图</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%9F%A5%E7%9C%8B%E6%95%B0%E6%8D%AE%E5%BA%93%E3%80%81%E8%A1%A8%E3%80%81%E8%A7%86%E5%9B%BE"><span class="toc-number">8.2.4.</span> <span class="toc-text">查看数据库、表、视图</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%8F%8F%E8%BF%B0%E6%95%B0%E6%8D%AE%E5%BA%93%E3%80%81%E8%A1%A8%E3%80%81%E8%A7%86%E5%9B%BE"><span class="toc-number">8.2.5.</span> <span class="toc-text">描述数据库、表、视图</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%90%91%E8%A1%A8%E4%B8%AD%E8%A3%85%E8%BD%BD%E6%95%B0%E6%8D%AE"><span class="toc-number">8.2.6.</span> <span class="toc-text">向表中装载数据</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%90%91%E8%A1%A8%E4%B8%AD%E6%8F%92%E5%85%A5%E6%95%B0%E6%8D%AE%E6%88%96%E4%BB%8E%E8%A1%A8%E4%B8%AD%E5%AF%BC%E5%87%BA%E6%95%B0%E6%8D%AE"><span class="toc-number">8.2.7.</span> <span class="toc-text">向表中插入数据或从表中导出数据</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%BA%94%E7%94%A8%E4%B8%BE%E4%BE%8B"><span class="toc-number">8.3.</span> <span class="toc-text">应用举例</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#Pig%E6%8A%80%E6%9C%AF"><span class="toc-number">9.</span> <span class="toc-text">Pig技术</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%AE%89%E8%A3%85Pig"><span class="toc-number">9.1.</span> <span class="toc-text">安装Pig</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%AE%9E%E9%AA%8C%E6%93%8D%E4%BD%9C"><span class="toc-number">9.2.</span> <span class="toc-text">实验操作</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%88%9B%E5%BB%BA%E6%96%87%E4%BB%B6%E5%B9%B6%E4%B8%8A%E4%BC%A0HDFS"><span class="toc-number">9.2.1.</span> <span class="toc-text">创建文件并上传HDFS</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%AE%9E%E9%AA%8C%E6%93%8D%E4%BD%9C-1"><span class="toc-number">9.2.2.</span> <span class="toc-text">实验操作</span></a></li></ol></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#Sqoop%E6%8A%80%E6%9C%AF"><span class="toc-number">10.</span> <span class="toc-text">Sqoop技术</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%AE%89%E8%A3%85Sqoop"><span class="toc-number">10.1.</span> <span class="toc-text">安装Sqoop</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%AE%9E%E9%AA%8C%E6%93%8D%E4%BD%9C-2"><span class="toc-number">10.2.</span> <span class="toc-text">实验操作</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%88%9B%E5%BB%BA%E6%95%B0%E6%8D%AE%E6%96%87%E4%BB%B6"><span class="toc-number">10.2.1.</span> <span class="toc-text">创建数据文件</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Sqoop%E7%9A%84%E6%95%B0%E6%8D%AE%E5%AF%BC%E5%85%A5"><span class="toc-number">10.2.2.</span> <span class="toc-text">Sqoop的数据导入</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%AF%BC%E5%85%A5HDFS%E4%B8%AD"><span class="toc-number">10.2.2.1.</span> <span class="toc-text">导入HDFS中</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%AF%BC%E5%85%A5HIVE%E4%B8%AD"><span class="toc-number">10.2.2.2.</span> <span class="toc-text">导入HIVE中</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%AF%BC%E5%85%A5%E8%A1%A8%E6%95%B0%E6%8D%AE%E5%AD%90%E9%9B%86"><span class="toc-number">10.2.2.3.</span> <span class="toc-text">导入表数据子集</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Sqoop%E7%9A%84%E6%95%B0%E6%8D%AE%E5%AF%BC%E5%87%BA"><span class="toc-number">10.2.3.</span> <span class="toc-text">Sqoop的数据导出</span></a></li></ol></li></ol></li></ol></div></div><div class="card-widget card-recent-post"><div class="item-headline"><i class="fas fa-history"></i><span>最新文章</span></div><div class="aside-list"><div class="aside-list-item"><a class="thumbnail" href="/2023/03/04/00-Mysql%E5%9F%BA%E7%A1%80%E7%AF%87/" title="00_Mysql基础篇"><img src="/img/bg/bg6.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="00_Mysql基础篇"/></a><div class="content"><a class="title" href="/2023/03/04/00-Mysql%E5%9F%BA%E7%A1%80%E7%AF%87/" title="00_Mysql基础篇">00_Mysql基础篇</a><time datetime="2023-03-04T01:54:28.000Z" title="发表于 2023-03-04 09:54:28">2023-03-04</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2023/03/04/04-%E6%97%A5%E5%BF%97%E4%B8%8E%E5%A4%87%E4%BB%BD%E7%AF%87/" title="04_日志与备份篇"><img src="/img/bg/bg1.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="04_日志与备份篇"/></a><div class="content"><a class="title" href="/2023/03/04/04-%E6%97%A5%E5%BF%97%E4%B8%8E%E5%A4%87%E4%BB%BD%E7%AF%87/" title="04_日志与备份篇">04_日志与备份篇</a><time datetime="2023-03-04T01:05:10.000Z" title="发表于 2023-03-04 09:05:10">2023-03-04</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2023/03/04/03-%E4%BA%8B%E5%8A%A1%E7%AF%87/" title="03_事务篇"><img src="/img/bg/bg8.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="03_事务篇"/></a><div class="content"><a class="title" href="/2023/03/04/03-%E4%BA%8B%E5%8A%A1%E7%AF%87/" title="03_事务篇">03_事务篇</a><time datetime="2023-03-04T01:04:13.000Z" title="发表于 2023-03-04 09:04:13">2023-03-04</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2023/03/03/02-MySQL%E7%B4%A2%E5%BC%95%E5%8F%8A%E8%B0%83%E4%BC%98%E7%AF%87/" title="02_MySQL索引及调优篇"><img src="/img/bg/bg7.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="02_MySQL索引及调优篇"/></a><div class="content"><a class="title" href="/2023/03/03/02-MySQL%E7%B4%A2%E5%BC%95%E5%8F%8A%E8%B0%83%E4%BC%98%E7%AF%87/" title="02_MySQL索引及调优篇">02_MySQL索引及调优篇</a><time datetime="2023-03-03T13:17:57.000Z" title="发表于 2023-03-03 21:17:57">2023-03-03</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2023/03/03/01-MySQL%E6%9E%B6%E6%9E%84%E7%AF%87/" title="01_MySQL架构篇"><img src="/img/bg/bg7.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="01_MySQL架构篇"/></a><div class="content"><a class="title" href="/2023/03/03/01-MySQL%E6%9E%B6%E6%9E%84%E7%AF%87/" title="01_MySQL架构篇">01_MySQL架构篇</a><time datetime="2023-03-03T13:01:40.000Z" title="发表于 2023-03-03 21:01:40">2023-03-03</time></div></div></div></div></div></div></main><footer id="footer" style="background-image: url('/img/bg/bg7.jpg')"><div id="footer-wrap"><div class="copyright">&copy;2021 - 2023 By pepsi-wyl</div><div class="framework-info"><span>框架 </span><a target="_blank" rel="noopener" href="https://hexo.io">Hexo</a><span class="footer-separator">|</span><span>主题 </span><a target="_blank" rel="noopener" href="https://github.com/jerryc127/hexo-theme-butterfly">Butterfly</a></div><div class="footer_custom_text"><a target="_blank" href="https://beian.miit.gov.cn" style="display:inline-block;text-decoration:none;height:20px;line-height:20px;">豫ICP备2022003015号-2</a> <br /> <a target="_blank" href="https://www.beian.gov.cn/portal/registerSystemInfo?recordcode=41052202001366" style="display:inline-block;text-decoration:none;height:20px;line-height:20px;">豫公网安备 41052202001366号</a></div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="阅读模式"><i class="fas fa-book-open"></i></button><button id="translateLink" type="button" title="简繁转换">简</button><button id="darkmode" type="button" title="浅色和深色模式转换"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="单栏和双栏切换"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside_config" type="button" title="设置"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="目录"><i class="fas fa-list-ul"></i></button><button id="go-up" type="button" title="回到顶部"><i class="fas fa-arrow-up"></i></button></div></div><div id="local-search"><div class="search-dialog"><nav class="search-nav"><span class="search-dialog-title">搜索</span><span id="loading-status"></span><button class="search-close-button"><i class="fas fa-times"></i></button></nav><div class="is-center" id="loading-database"><i class="fas fa-spinner fa-pulse"></i><span>  数据库加载中</span></div><div class="search-wrap"><div id="local-search-input"><div class="local-search-box"><input class="local-search-box--input" placeholder="搜索文章" type="text"/></div></div><hr/><div id="local-search-results"></div></div></div><div id="search-mask"></div></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="/js/tw_cn.js"></script><script src="https://cdn.jsdelivr.net/npm/medium-zoom/dist/medium-zoom.min.js"></script><script src="/js/search/local-search.js"></script><div class="js-pjax"></div><script src="https://widget.qweather.net/simple/static/js/he-simple-common.js?v=2.0"></script><script src="/js/weather.js"></script><script src="/js/timing.js"></script><script src="/js/weibo.js"></script><script id="canvas_nest" defer="defer" color="0,0,255" opacity="0.7" zIndex="-1" count="99" mobile="true" src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/dist/canvas-nest.min.js"></script><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/dist/activate-power-mode.min.js"></script><script>POWERMODE.colorful = true;
POWERMODE.shake = true;
POWERMODE.mobile = false;
document.body.addEventListener('input', POWERMODE);
</script><script id="click-show-text" src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/dist/click-show-text.min.js" data-mobile="false" data-text="富强,民主,文明,和谐,自由,平等,公正,法治,爱国,敬业,诚信,友善" data-fontsize="15px" data-random="false" async="async"></script><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script></div></body></html>